\documentclass[12pt,fleqn]{article}\usepackage{../common}
\begin{document}
Ders 19

Eslenik Gradyan (Conjugate Gradient) Yontemi 

Arnoldi metotu Gram-Schmidt'e tam olmsa da benzeyen bir yontemdir ve bir
ortogonal baz ortaya cikartir. Bu baz, Krylov altuzayinin bazidir, ki bu
altuzaydaki her yeni baz vektor, $e$'nin baska bir ustu alinip carpilarak
elde edilir. Fakat bu pek iyi bir baz degildir, bazlarin ortogonalize
edilmesi gerekir, ve Arnoldi'nin yaptigi budur. 

Arnoldi-Lanczos yontemi ozdegerler (eigenvalue) bulmak icin de kullanilir.

\[ AQ = QH \]

esitligindeki $H$ matrisinin alt-matrisine bakilirsa, aranilan ozdegerler
buradan okunabilir. Bu alt-matris simetrik ve ust kosegendir.
(upperdiagonal). 

\[ H = Q^{-1}AQ \]

formulunde $H,A$ matrisleri birbirine benzerdir (similar) ve benzer
matrislerin ozdegerleri aynidir. 

Bu kavramlardan soyle bir bahsetmek istedim, belki gunun birinde cok buyuk
bir matrisin ozdegerlerini bulmak istersiniz, aklinizda olsun. Yazilim
\verb!arpack! bunun icin kullanilabiliyor. Bahsi yaptik bir diger sebep
lineer cebirin yarisi lineer sistemlerse, diger yarisi ozdeger
problemleridir denebilir. Buraya gelmisken ustteki ozdeger yonteminden
bahsetmemek olmazdi. 

Konumuza donelim. 

$A$ pozitif kesin ve simetrik olmali. Eger degilse birazdan gosgterecegimiz
formulleri kullanmak biraz riskli olur, isleyebilirler ama garanti olmaz. 

$r_K = b - Ax_k $, $K_k$'ye ortogonal, $x_k \in \mathscr{K}_K$. 

Demek ki $x_k$'yi ozyineli olarak yaratabiliriz, ve her adimda sadece $A$
ile carpmamiz gerekir. Ustteki formulde $A$ ile carpim olduguna gore, $r_K$
bir sonraki uzay $k+1$ icinde olacaktir. Arnoldi'den biliyoruz ki $q_{k+1}$
ayni uzay icindedir. O zaman 

$r_k$, $q_{k+1}$'in bir katidir. Yani $r$ ile gosterilen ``artiklar
(residuals)'' birbirine ortogonal. Yani 

\[ r_i^Tr_k = 0, \ i < k \]

Artiklarin birbirine ortogonal olmasinin sebebi iclerinde $A$ olmasi. 

Baslangic degerleri

\[ d_0 = b \]

\[ x_0 = 0 \]

\[ r_0 = b - Ax_0  = b\]

Simetrik Pozitif Kesin $A$ Icin Eslenik Gradyan Metodu

\begin{lstlisting}[language=Matlab,mathescape,numbers=left]
$\alpha_k = r_{k-1}^T r_{k-1} / d_{k-1}^T A d_{k-1}$
$\alpha_k = \alpha_{k-1} + \alpha_k d_{k-1}$
$r_k = r_{k-1} - \alpha_k Ad_{k-1}$
$\beta_k = r_k^Tr_k / r_{k-1}^Tr_{k-1}$
$d_k = r_k + \beta_k d_{k-1}$
\end{lstlisting}





















\end{document}
