\documentclass[12pt,fleqn]{article}\usepackage{../common}
\begin{document}
Lineer Regresyon

Bir hedef degiskeninin bir veya daha fazla kaynak degiskenine olan
baglantisini bulmak icin en basit yontemlerden biri bu iliskinin lineer
oldugunu kabul etmektir, ve degiskenlerin carpildigi agirliklari bulmak
icin En Az Kareler (Least Squares) en iyi bilinen yontemlerden biri. En Az
Kareleri daha once pek cok degisik ders notlarinda, yazida turettik. Mesela
{\em Cok Degiskenli Calculus Ders 9}, {\em Lineer Cebir Ders 15}, ya da
Uygulamali Matematik yazilarindan {\em Regresyon, En Az Kareler (Least
  Squares)} yazilarinda. 

Satis ve Reklamlar

\begin{minted}[fontsize=\footnotesize]{python}
import pandas as pd
import statsmodels.formula.api as smf
df = pd.read_csv('adv.csv',usecols=[1,2,3,4])
print df[:2]
\end{minted}

\begin{verbatim}
      TV  Radio  Newspaper  Sales
0  230.1   37.8       69.2   22.1
1   44.5   39.3       45.1   10.4
\end{verbatim}

\begin{minted}[fontsize=\footnotesize]{python}
results = smf.ols('Sales ~ 1 + TV', data=df).fit()
print results.summary()
\end{minted}

\begin{verbatim}
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  Sales   R-squared:                       0.612
Model:                            OLS   Adj. R-squared:                  0.610
Method:                 Least Squares   F-statistic:                     312.1
Date:                Fri, 14 Mar 2014   Prob (F-statistic):           1.47e-42
Time:                        17:28:29   Log-Likelihood:                -519.05
No. Observations:                 200   AIC:                             1042.
Df Residuals:                     198   BIC:                             1049.
Df Model:                           1                                         
==============================================================================
                 coef    std err          t      P>|t|      [95.0% Conf. Int.]
------------------------------------------------------------------------------
Intercept      7.0326      0.458     15.360      0.000         6.130     7.935
TV             0.0475      0.003     17.668      0.000         0.042     0.053
==============================================================================
Omnibus:                        0.531   Durbin-Watson:                   1.935
Prob(Omnibus):                  0.767   Jarque-Bera (JB):                0.669
Skew:                          -0.089   Prob(JB):                        0.716
Kurtosis:                       2.779   Cond. No.                         338.
==============================================================================
\end{verbatim}

\begin{minted}[fontsize=\footnotesize]{python}
results = smf.ols('Sales ~ 1 + Radio', data=df).fit()
print results.summary()
\end{minted}

\begin{verbatim}
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  Sales   R-squared:                       0.332
Model:                            OLS   Adj. R-squared:                  0.329
Method:                 Least Squares   F-statistic:                     98.42
Date:                Fri, 14 Mar 2014   Prob (F-statistic):           4.35e-19
Time:                        17:41:33   Log-Likelihood:                -573.34
No. Observations:                 200   AIC:                             1151.
Df Residuals:                     198   BIC:                             1157.
Df Model:                           1                                         
==============================================================================
                 coef    std err          t      P>|t|      [95.0% Conf. Int.]
------------------------------------------------------------------------------
Intercept      9.3116      0.563     16.542      0.000         8.202    10.422
Radio          0.2025      0.020      9.921      0.000         0.162     0.243
==============================================================================
Omnibus:                       19.358   Durbin-Watson:                   1.946
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               21.910
Skew:                          -0.764   Prob(JB):                     1.75e-05
Kurtosis:                       3.544   Cond. No.                         51.4
==============================================================================
\end{verbatim}

\begin{minted}[fontsize=\footnotesize]{python}
results = smf.ols('Sales ~ 1 + Newspaper', data=df).fit()
print results.summary()
\end{minted}

\begin{verbatim}
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  Sales   R-squared:                       0.052
Model:                            OLS   Adj. R-squared:                  0.047
Method:                 Least Squares   F-statistic:                     10.89
Date:                Fri, 14 Mar 2014   Prob (F-statistic):            0.00115
Time:                        17:42:20   Log-Likelihood:                -608.34
No. Observations:                 200   AIC:                             1221.
Df Residuals:                     198   BIC:                             1227.
Df Model:                           1                                         
==============================================================================
                 coef    std err          t      P>|t|      [95.0% Conf. Int.]
------------------------------------------------------------------------------
Intercept     12.3514      0.621     19.876      0.000        11.126    13.577
Newspaper      0.0547      0.017      3.300      0.001         0.022     0.087
==============================================================================
Omnibus:                        6.231   Durbin-Watson:                   1.983
Prob(Omnibus):                  0.044   Jarque-Bera (JB):                5.483
Skew:                           0.330   Prob(JB):                       0.0645
Kurtosis:                       2.527   Cond. No.                         64.7
==============================================================================
\end{verbatim}

\end{document}
