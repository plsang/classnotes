\documentclass[12pt,fleqn]{article}\usepackage{../common}
\begin{document}
Lineer Regresyon

Bir hedef degiskeninin bir veya daha fazla kaynak degiskenine olan
baglantisini bulmak icin en basit yontemlerden biri bu iliskinin lineer
oldugunu kabul etmektir, ve degiskenlerin carpildigi agirliklari bulmak
icin En Az Kareler (Least Squares) en iyi bilinen yontemlerden biri. En Az
Kareleri daha once pek cok degisik ders notlarinda, yazida turettik. Mesela
{\em Cok Degiskenli Calculus Ders 9}, {\em Lineer Cebir Ders 15}, ya da
Uygulamali Matematik yazilarindan {\em Regresyon, En Az Kareler (Least
  Squares)} yazilarinda. 

Satis ve Reklamlar

\begin{minted}[fontsize=\footnotesize]{python}
import pandas as pd
import statsmodels.formula.api as smf
df = pd.read_csv('adv.csv',usecols=[1,2,3])
print df[:2]
\end{minted}

\begin{verbatim}
      TV  Radio  Newspaper
0  230.1   37.8       69.2
1   44.5   39.3       45.1
\end{verbatim}

\begin{minted}[fontsize=\footnotesize]{python}
results = smf.ols('Sales ~ 1 + TV', data=df).fit()
print results.summary()
\end{minted}

\begin{verbatim}
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  Sales   R-squared:                       0.612
Model:                            OLS   Adj. R-squared:                  0.610
Method:                 Least Squares   F-statistic:                     312.1
Date:                Fri, 14 Mar 2014   Prob (F-statistic):           1.47e-42
Time:                        17:28:29   Log-Likelihood:                -519.05
No. Observations:                 200   AIC:                             1042.
Df Residuals:                     198   BIC:                             1049.
Df Model:                           1                                         
==============================================================================
                 coef    std err          t      P>|t|      [95.0% Conf. Int.]
------------------------------------------------------------------------------
Intercept      7.0326      0.458     15.360      0.000         6.130     7.935
TV             0.0475      0.003     17.668      0.000         0.042     0.053
==============================================================================
Omnibus:                        0.531   Durbin-Watson:                   1.935
Prob(Omnibus):                  0.767   Jarque-Bera (JB):                0.669
Skew:                          -0.089   Prob(JB):                        0.716
Kurtosis:                       2.779   Cond. No.                         338.
==============================================================================
\end{verbatim}

\end{document}
