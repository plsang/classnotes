\documentclass[12pt,fleqn]{article}\usepackage{../common}
\begin{document}
Oge Kumeleri Bulmak ve Ikisel Matris Ayristirmasi (Binary Matrix Factorization)

Veri madenciligi denince pek cok kisinin aklina gelen ilk ornek, aslinda,
sýk bulunan öðe kumeleri (frequent itemsets) ornegidir: "filanca ulkeden
sitemize gelen musterilerin ayni zamanda vs ozelliklerinin oldugunu da
kesfettik" gibi. 

Benzer bir ornek, ki bu alan oge kumelerinin aslinda en onemli cikis
sebeplerinden birisidir, alisveris sepeti analizidir. Musterinin her
alisverisinde sepetinde belli mallar vardir, ve bu mallarin hangilerinin
ayni anda, ayni sepette oldugu analiz edilmeye ugrasilir. Eger surekli
ekmek ve recel ayni anda aliniyorsa, bu bilgi kullanilarak belki mallarin
daha iyi konumlandirilmasi yapilacaktir, vs. Sýk bulunan oge kumeleri
teknikleri bazen degisik adlar altinda da gecebiliyor, mesela alaka
madenciligi (association mining) gibi. Algoritma olarak kullanilan pek cok
teknik var, APriori iyi bilinenlerden, FPGrowth ondan daha hizli calisan ve
son zamanlarda daha tercih edilmeye baslanan bir teknik.

Alternatif bir teknik ikisel matris ayristirmasi (binary matrix
factorization -BMF-) [3]. Aynen SVD'de oldugu gibi BMF de bir matrisi
ayristirir, fakat uc matris yerine iki matrise ayristirir. Ayristirma
oncesi hangi kerte (rank) $k$ degerine gecmek istedigimizi biz
belirtiriz. BMF'nin oge kumeleri madenciligi icin faydasi surada: oge
kumeleri ararken baktigimiz ogeler kategorik seylerdir, alisveris sepeti
orneginde mesela ekmek, recel gibi. Kategorik ogeleri daha once one-hot
kodlamasi (encoding) ile 1/0 degerleri tasiyan yeni kolonlara
gecirebildigimizi gormustuk. Yani tamamen kategorik degerler tasiyan
veriler tamamen 1/0 tasiyacak sekilde tekrar kodlanabilir, yani ikisel
matris haline getirilebilir. Bu ikisel matrisi ayristirdigimiz zaman ise
ayni zamanda boyut indirgemesi yapmis oluruz, ve bir anlamda ana matrisi
``ozetleriz''. Iste bu ozet, ozellikle carpilan ``baz'' matris, oge
kumelerinin hangileri oldugu hakkinda ipuclari iceriyor olabilir.

Bir ornek uzerinde gorelim, mesela altta Alice (A), Bob Marley (B) ve Prens
Charles (C) verileri var. Bu kisiler icin saci uzun mu (long-haired), ünlü
mü (well-known) ve bay mý (male) verileri var. 

\includegraphics[height=5cm]{abc.png}

Bu matris uzerinde ikisel ayristirma yaparsak, 

\includegraphics[height=2cm]{abc_res.png}

Sonuca dikkatle bakalim, ozellikle sol taraftaki carpilan ``baz'' matrisi
onemli. {\em Matris Carpimi} yazisini hatirlarsak, bu yazidaki kolon
kombinasyon bakisini kullanalim, 

\begin{minted}{python}
import nimfa
import pandas as pd
import scipy.sparse as sp

def __fact_factor(X):
    return X.todense() if sp.isspmatrix(X) else X

A = np.array([[1., 1., 0],
              [1., 1., 1.],
              [0, 1., 1.]])

fctr = nimfa.mf(A,
              seed = "nndsvd", 
              rank = 2, 
              method = "bmf", 
              max_iter = 40, 
              initialize_only = True,
              lambda_w = 1.1,
              lambda_h = 1.1)

res = nimfa.mf_run(fctr)

threshold = 0.2
res1 = __fact_factor(res.basis())
res2 = __fact_factor(res.coef())
res1 = np.abs(np.round(res1 - 0.5 + threshold))
res2 = np.abs(np.round(res2 - 0.5 + threshold))
res1 = pd.DataFrame(res1, index=['long-haired','well-known','male'])
res2 = pd.DataFrame(res2, columns=['A','B','C'])
print res1
print '\n'
print res2
\end{minted}

\begin{verbatim}
             0  1
long-haired  1  0
well-known   1  1
male         0  1


   A  B  C
0  1  0  0
1  0  1  1
\end{verbatim}

\begin{minted}{python}
data = [
['outlook=sunny', 'temparature=hot', 'humidity=high', 'windy=false', 'play=no'],
['outlook=sunny', 'temparature=hot', 'humidity=high', 'windy=true', 'play=no'],
['outlook=overcast', 'temparature=hot', 'humidity=high', 'windy=false', 'play=yes'],
['outlook=rainy', 'temparature=mild', 'humidity=high', 'windy=false', 'play=yes'],
['outlook=rainy', 'temparature=cool', 'humidity=normal', 'windy=false', 'play=yes'],
['outlook=rainy', 'temparature=cool', 'humidity=normal', 'windy=true', 'play=no'],
['outlook=overcast', 'temparature=cool', 'humidity=normal', 'windy=true', 'play=yes'],
['outlook=sunny', 'temparature=mild', 'humidity=high', 'windy=false', 'play=no'],
['outlook=sunny', 'temparature=cool', 'humidity=normal', 'windy=false', 'play=yes'],
['outlook=rainy', 'temparature=mild', 'humidity=normal', 'windy=false', 'play=yes'],
['outlook=sunny', 'temparature=mild', 'humidity=normal', 'windy=true', 'play=yes'],
['outlook=overcast', 'temparature=mild', 'humidity=high', 'windy=true', 'play=yes'],
['outlook=overcast', 'temparature=hot', 'humidity=normal', 'windy=false', 'play=yes'],
['outlook=rainy', 'temparature=mild', 'humidity=high', 'windy=true', 'play=no']
]

from sklearn.feature_extraction import DictVectorizer
import pandas as pd, re

def one_hot_dataframe(data, cols, replace=False):
    vec = DictVectorizer()
    mkdict = lambda row: dict((col, row[col]) for col in cols)
    vecData = pd.DataFrame(vec.fit_transform(data[cols].apply(mkdict, axis=1)).toarray())
    vecData.columns = vec.get_feature_names()
    vecData.index = data.index
    if replace is True:
        data = data.drop(cols, axis=1)
        data = data.join(vecData)
    return (data, vecData, vec)

cols = ['outlook','temparature','humidity','windy','play']
df = pd.DataFrame(data,columns=cols)
# kolon ismini veriden cikart, cunku tekrar geri koyulacak
# fpgrowth icin veri icinde olmasi lazim
df = df.applymap(lambda x: re.sub('.*?=','',x))
df2, _, _ = one_hot_dataframe(df, cols, replace=True)
# tek ornek ekrana bas
print df2.ix[0]
\end{minted}

\begin{verbatim}
humidity=high       1
humidity=normal     0
outlook=overcast    0
outlook=rainy       0
outlook=sunny       1
play=no             1
play=yes            0
temparature=cool    0
temparature=hot     1
temparature=mild    0
windy=false         1
windy=true          0
Name: 0, dtype: float64
\end{verbatim}


\begin{minted}{python}
import nimfa
import scipy.sparse as sp

fctr = nimfa.mf(np.array(df2).T, seed = "nndsvd", 
              rank = 4, method = "bmf", 
              max_iter = 40, initialize_only = True,
              lambda_w = 1.1, lambda_h = 1.1)

res = nimfa.mf_run(fctr)

threshold = 0.2
res1 = __fact_factor(res.basis())
res2 = __fact_factor(res.coef())
res1 = np.abs(np.round(res1 - 0.5 + threshold))
res2=  np.abs(np.round(res2 - 0.5 + threshold))
res1 = pd.DataFrame(res1,index=df2.columns)
print res1
\end{minted}

\begin{verbatim}
                  0  1  2  3
humidity=high     1  0  0  1
humidity=normal   0  1  0  0
outlook=overcast  0  0  1  0
outlook=rainy     1  0  0  0
outlook=sunny     0  0  0  1
play=no           0  0  0  1
play=yes          0  1  1  0
temparature=cool  0  0  0  0
temparature=hot   0  0  0  0
temparature=mild  1  0  0  0
windy=false       0  0  1  0
windy=true        1  0  0  0
\end{verbatim}

\begin{minted}{python}
print np.array(df2.columns)[res1.ix[:,0] == 1]
print np.array(df2.columns)[res1.ix[:,1] == 1]
print np.array(df2.columns)[res1.ix[:,2] == 1]
print np.array(df2.columns)[res1.ix[:,3] == 1]
\end{minted}

\begin{verbatim}
['humidity=high' 'outlook=rainy' 'temparature=mild' 'windy=true']
['humidity=normal' 'play=yes']
['outlook=overcast' 'play=yes' 'windy=false']
['humidity=high' 'outlook=sunny' 'play=no']
\end{verbatim}


\begin{minted}{python}
import fp
items = fp.fpgrowth(data, minsup=6)
for x in items:
    if len(x) > 1: print x
\end{minted}

\begin{verbatim}
<fp.node instance at 0x5017ef0>
   Null Set   1
     play=yes   9
       humidity=high   1
         windy=true   1
           temparature=mild   1
       windy=false   6
         humidity=high   2
           temparature=mild   1
         humidity=normal   4
           temparature=mild   1
       humidity=normal   2
         windy=true   2
           temparature=mild   1
     humidity=high   2
       windy=true   2
         temparature=mild   1
     windy=false   2
       humidity=high   2
         temparature=mild   1
     humidity=normal   1
       windy=true   1
   Null Set   1
     play=yes   6
   Null Set   1
     play=yes   6
set(['play=yes', 'humidity=normal'])
set(['play=yes', 'windy=false'])
\end{verbatim}

Kaynaklar

[1] Ian H. Witten, Eibe Frank, Mark A. Hall, {\em Data Mining Practical Machine Learning Tools and Techniques}

[2] Harrington, P., {\em Machine Learning in Action}

[3] \url{http://www.mpi-inf.mpg.de/~pmiettin/slides/BooleanMatrixFactorizationsForDataMining_Antwerp_slides.pdf}

\end{document}
