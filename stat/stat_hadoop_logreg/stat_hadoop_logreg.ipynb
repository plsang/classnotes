{
 "metadata": {
  "name": "stat_hadoop_logreg"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "source": [
      "Paralel Lojistik Regresyon, Hadoop\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "!ssh localhost -l hduser /home/hduser/Downloads/hadoop*/bin/stop-all.sh\n",
      "!ssh localhost -l hduser /home/hduser/Downloads/hadoop*/bin/start-all.sh\n"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "no jobtracker to stop\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "localhost: no tasktracker to stop\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "no namenode to stop\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "localhost: no datanode to stop\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "localhost: no secondarynamenode to stop\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting namenode, logging to /home/hduser/Downloads/hadoop-1.0.4/libexec/../logs/hadoop-hduser-namenode-burak-Aspire-S3.out\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "localhost: starting datanode, logging to /home/hduser/Downloads/hadoop-1.0.4/libexec/../logs/hadoop-hduser-datanode-burak-Aspire-S3.out\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "localhost: starting secondarynamenode, logging to /home/hduser/Downloads/hadoop-1.0.4/libexec/../logs/hadoop-hduser-secondarynamenode-burak-Aspire-S3.out\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting jobtracker, logging to /home/hduser/Downloads/hadoop-1.0.4/libexec/../logs/hadoop-hduser-jobtracker-burak-Aspire-S3.out\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "localhost: starting tasktracker, logging to /home/hduser/Downloads/hadoop-1.0.4/libexec/../logs/hadoop-hduser-tasktracker-burak-Aspire-S3.out\r\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!sort --random-sort  testSet.txt > /tmp/testSet.txt"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ssh localhost -l hduser /home/hduser/Downloads/hadoop*/bin/hadoop dfs -copyFromLocal /tmp/testSet.txt /user/hduser"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "copyFromLocal: Target /user/hduser/testSet.txt already exists\r\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print open(\"mapper.py\").read()"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "#!/usr/bin/python\n",
        "import os,sys,itertools\n",
        "import numpy as np\n",
        "from numpy import linalg as la\n",
        "os.environ['MPLCONFIGDIR']='/tmp' \n",
        "import pandas as pd\n",
        "\n",
        "def sigmoid(arr):\n",
        "    return 1.0/(1+np.exp(-arr))\n",
        "\n",
        "def stoc_grad_ascent0(data_mat, label_mat):\n",
        "    m,n = data_mat.shape\n",
        "    label_mat=label_mat.reshape((m,1))\n",
        "    theta = np.ones((n,1))\n",
        "    sum = np.zeros((n,1))\n",
        "    for i in range(m):\n",
        "        h = sigmoid(np.sum(np.dot(data_mat[i],theta)))\n",
        "        error = label_mat[i] - h\n",
        "        sum += data_mat[i].reshape((n,1)) * error\n",
        "    return sum\n",
        "\n",
        "data = pd.read_csv(sys.stdin,header=None,sep='\\t')\n",
        "xy = np.array(data.ix[:,0:2])\n",
        "labels = data.ix[:,2].T\n",
        "sum = np.array(stoc_grad_ascent0(xy,labels))\n",
        "print sum\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print open(\"reducer.py\").read()"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 2
    }
   ]
  }
 ]
}