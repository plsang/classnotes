{
 "metadata": {
  "name": "meanshift"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pandas import *\n",
      "df1 = read_csv(\"synthetic.txt\",sep=\"   \")\n"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "!ssh localhost -l hduser /home/hduser/Downloads/hadoop*/bin/stop-all.sh\n",
      "!ssh localhost -l hduser /home/hduser/Downloads/hadoop*/bin/start-all.sh\n"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "stopping jobtracker\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "localhost: stopping tasktracker\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "stopping namenode\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "localhost: stopping datanode\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "localhost: stopping secondarynamenode\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting namenode, logging to /home/hduser/Downloads/hadoop-1.0.4/libexec/../logs/hadoop-hduser-namenode-burak-Aspire-S3.out\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "localhost: starting datanode, logging to /home/hduser/Downloads/hadoop-1.0.4/libexec/../logs/hadoop-hduser-datanode-burak-Aspire-S3.out\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "localhost: starting secondarynamenode, logging to /home/hduser/Downloads/hadoop-1.0.4/libexec/../logs/hadoop-hduser-secondarynamenode-burak-Aspire-S3.out\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting jobtracker, logging to /home/hduser/Downloads/hadoop-1.0.4/libexec/../logs/hadoop-hduser-jobtracker-burak-Aspire-S3.out\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "localhost: starting tasktracker, logging to /home/hduser/Downloads/hadoop-1.0.4/libexec/../logs/hadoop-hduser-tasktracker-burak-Aspire-S3.out\r\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ssh localhost -l hduser /home/hduser/Downloads/hadoop*/bin/hadoop dfs -copyFromLocal $HOME/Documents/classnotes/stat/stat_hadoop_kmeans/synthetic.txt /user/hduser"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "copyFromLocal: Target /user/hduser/synthetic.txt already exists\r\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print open(\"mapper.py\").read()"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "#!/usr/bin/python\n",
        "import os,sys,itertools\n",
        "import numpy as np\n",
        "from numpy import linalg as la\n",
        "os.environ['MPLCONFIGDIR']='/tmp' \n",
        "import pandas as pd\n",
        "\n",
        "centers = pd.read_csv(\"/tmp/centers.csv\",header=None,sep=\",\")\n",
        "\n",
        "def dist(vect,x):\n",
        "    return np.fromiter(itertools.imap(np.linalg.norm, vect-x),dtype=np.float)\n",
        "\n",
        "def closest(x):\n",
        "    d = dist(np.array(centers)[:,1:3],np.array(x))\n",
        "    return np.argmin(d)\n",
        "\n",
        "comb = lambda x: str(x[0])+\":\"+str(x[1])\n",
        "\n",
        "df = pd.read_csv(sys.stdin,header=None,sep=\"   \")\n",
        "df['cluster'] = df.apply(closest,axis=1)\n",
        "df['coord'] = df.apply(comb,axis=1)\n",
        "df.to_csv(sys.stdout, sep='\\t',index=False, cols=['cluster','coord'],\n",
        "          header=None)\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print open(\"reducer.py\").read()"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "#!/usr/bin/python\n",
        "import os,sys,itertools\n",
        "import numpy as np\n",
        "from numpy import linalg as la\n",
        "os.environ['MPLCONFIGDIR']='/tmp' \n",
        "import pandas as pd\n",
        "\n",
        "def coords(x):\n",
        "    return pd.Series(np.array(str(x).split(\":\"),dtype=np.float64))\n",
        "\n",
        "df = pd.read_csv(sys.stdin,sep=\"\\t\",names=['cluster','coord'])\n",
        "df2 = df['coord'].apply(coords)\n",
        "df3 = df.combine_first(df2)\n",
        "df4 = df3.groupby('cluster').mean()\n",
        "df4.to_csv(sys.stdout, sep=',',header=None)\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 2
    }
   ]
  }
 ]
}