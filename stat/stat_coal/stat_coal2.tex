%% This file was auto-generated by IPython.
%% Conversion from the original notebook file:
%% stat_coal2.ipynb
%%
\documentclass[11pt,english,fleqn]{article}

%% This is the automatic preamble used by IPython.  Note that it does *not*
%% include a documentclass declaration, that is added at runtime to the overall
%% document.

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{ucs}
\usepackage[utf8x]{inputenc}

% needed for markdown enumerations to work
\usepackage{enumerate}

% Slightly bigger margins than the latex defaults
\usepackage{geometry}
\geometry{verbose,tmargin=3cm,bmargin=3cm,lmargin=2.5cm,rmargin=2.5cm}

% Define a few colors for use in code, links and cell shading
\usepackage{color}
\definecolor{orange}{cmyk}{0,0.4,0.8,0.2}
\definecolor{darkorange}{rgb}{.71,0.21,0.01}
\definecolor{darkgreen}{rgb}{.12,.54,.11}
\definecolor{myteal}{rgb}{.26, .44, .56}
\definecolor{gray}{gray}{0.45}
\definecolor{lightgray}{gray}{.95}
\definecolor{mediumgray}{gray}{.8}
\definecolor{inputbackground}{rgb}{.95, .95, .85}
\definecolor{outputbackground}{rgb}{.95, .95, .95}
\definecolor{traceback}{rgb}{1, .95, .95}

% Framed environments for code cells (inputs, outputs, errors, ...).  The
% various uses of \unskip (or not) at the end were fine-tuned by hand, so don't
% randomly change them unless you're sure of the effect it will have.
\usepackage{framed}

% remove extraneous vertical space in boxes
\setlength\fboxsep{0pt}

% codecell is the whole input+output set of blocks that a Code cell can
% generate.

% TODO: unfortunately, it seems that using a framed codecell environment breaks
% the ability of the frames inside of it to be broken across pages.  This
% causes at least the problem of having lots of empty space at the bottom of
% pages as new frames are moved to the next page, and if a single frame is too
% long to fit on a page, will completely stop latex from compiling the
% document.  So unless we figure out a solution to this, we'll have to instead
% leave the codecell env. as empty.  I'm keeping the original codecell
% definition here (a thin vertical bar) for reference, in case we find a
% solution to the page break issue.

%% \newenvironment{codecell}{%
%%     \def\FrameCommand{\color{mediumgray} \vrule width 1pt \hspace{5pt}}%
%%    \MakeFramed{\vspace{-0.5em}}}
%%  {\unskip\endMakeFramed}

% For now, make this a no-op...
\newenvironment{codecell}{}

 \newenvironment{codeinput}{%
   \def\FrameCommand{\colorbox{inputbackground}}%
   \MakeFramed{\advance\hsize-\width \FrameRestore}}
 {\unskip\endMakeFramed}

\newenvironment{codeoutput}{%
   \def\FrameCommand{\colorbox{outputbackground}}%
   \vspace{-1.4em}
   \MakeFramed{\advance\hsize-\width \FrameRestore}}
 {\unskip\medskip\endMakeFramed}

\newenvironment{traceback}{%
   \def\FrameCommand{\colorbox{traceback}}%
   \MakeFramed{\advance\hsize-\width \FrameRestore}}
 {\endMakeFramed}

% Use and configure listings package for nicely formatted code
\usepackage{listingsutf8}
\lstset{
  language=python,
  inputencoding=utf8x,
  extendedchars=\true,
  aboveskip=\smallskipamount,
  belowskip=\smallskipamount,
  xleftmargin=2mm,
  breaklines=true,
  basicstyle=\small \ttfamily,
  showstringspaces=false,
  keywordstyle=\color{blue}\bfseries,
  commentstyle=\color{myteal},
  stringstyle=\color{darkgreen},
  identifierstyle=\color{darkorange},
  columns=fullflexible,  % tighter character kerning, like verb
}

% The hyperref package gives us a pdf with properly built
% internal navigation ('pdf bookmarks' for the table of contents,
% internal cross-reference links, web links for URLs, etc.)
\usepackage{hyperref}
\hypersetup{
  breaklinks=true,  % so long urls are correctly broken across lines
  colorlinks=true,
  urlcolor=blue,
  linkcolor=darkorange,
  citecolor=darkgreen,
  }

% hardcode size of all verbatim environments to be a bit smaller
\makeatletter 
\g@addto@macro\@verbatim\small\topsep=0.5em\partopsep=0pt
\makeatother 

% Prevent overflowing lines due to urls and other hard-to-break entities.
\sloppy

\setlength{\mathindent}{0pt}
\setlength{\parindent}{0pt}
\setlength{\parskip}{8pt}
\begin{document}

MCMC, Degisim Nokta Hesabi, Gibbs Orneklemesi, Bayes Teorisi

Ingiltere'de 1851 ve 1962 yillari arasinda komur madenlerinde olan
kazalarin sayisi yillik olarak kayitli . Acaba bu kazalarin ``oraninin''
degisimine bakarak, degisimin oldugu seneyi bulabilir miyiz? Boyle bir
degisim ani neyi gosterir? Belki madenlerle alakali regulasyonlarda,
denetimlerde bir degisiklik olmustur, ve kaza orani azalmistir.

Bu hesabi yapabilmek icin ``degisim noktasi'' hesabi (change-point
analysis), ve Bayes kurali ile Bayes formullerini hesaplamamizi saglayan
Markov Chain Monte Carlo (MCMC) teknigine bakacagiz. Kazalarin sayisinin
tumunu iki Poisson dagiliminin ortak dagilimi (joint distribution)
uzerinden modelleyecegiz, ve bu dagilimlarin birinci Poisson'dan
ikincisine gectigi ani hesaplamaya ugrasacagiz.

Once Bayes, dagilimlar konusuna bir bakalim:

Poisson dagilimi
\[ p(y|\theta) = \frac{e^{-\theta}\theta^y}{y!} \]
Eldeki n tane veri noktasi $y=y_0, y_1,...,y_n$'nin hep birlikte
$\theta$ ile tanimli bir Poisson dagilimindan gelip gelmediginin ne
kadar mumkun oldugu (likelihood) hesabi soyledir:
\[ p(y|\theta) = \frac{e^{-n\theta}\theta^{\sum y_i}}{\prod y_i!}  \]
Formulun bolunen kismindaki tum y noktalari toplaniyor, bolen kisminde
ise tum y degerleri teker teker faktoryel hesabi sonrasi birbiri ile
carpiliyor.

Simdi yukaridaki $\theta$ degiskeni de noktasal bir deger yerine bir
``dagilima'', mesela $\theta$ Gamma dagilimina sahip olabilirdi:
$Gamma(\alpha, \beta)$. Formulde $\alpha$, $\beta$ sabit degerlerdir
(fonksiyon degiskeni degil). Gamma olasilik formulu soyledir:
\[ p(\theta) = \frac{\beta^\alpha}{\Gamma(\alpha)}\theta^{\alpha-1}e^{-\beta\theta} \]
O zaman $p(y|\theta)$ formulunu bulmak icin Bayes teorisini kullanmamiz
gerekecekti. Bayes teorisi bilindigi gibi
\[ p(\theta|y) = \frac{p(y|\theta)p(\theta)}{p(y)} \]\[ p(\theta|y) \propto p(y|\theta)p(\theta) \]
Ikinci formule dikkat, esitlik yerine orantili olma (proportional to)
isaretini kullaniyor. Sebep: bolen kismindaki p(y)'yi kaldirdik, sonuc
olarak soldaki $p(\theta|y)$ degeri artik bir dagilim degil -- bu bir
bakimdan onemli ama ornekleme amaci icin bir fark yaratmiyor,
basitlestirme amaciyla bunu yaptik, boylece $p(y)$'yi hesaplamamiz
gerekmeyecek, ama ornekleme uzerinden diger tum hesaplari hala
yapabiliriz. Tamam.

Simdi Bayes Teorisini Gamma oncul (apriori) ve Poisson mumkunlugu
(likelihood) uzerinden kullanirsak,
\[ 
p(\theta|y) = \frac{\beta^\alpha}{\Gamma(\alpha)}
\theta^{\alpha-1}e^{-\beta\theta} \times
\frac{e^{-n\theta}\theta^{\sum y}}{\prod y!} 
\]
Benzer terimleri yanyana getirelim:
\[ 
p(\theta|y) = \frac{\beta^\alpha}{\Gamma(\alpha)\prod y!}
\theta^{\alpha-1}\theta^{\sum y}e^{-\beta\theta} e^{-n\theta} 
\]
Simdi sol taraftaki bolumu atalim; yine usttekine benzer numara, bu
kisim gidince geri galan dagilim olamayacak, ama ona ``oranli'' baska
bir formul olacak.
\[ p(\theta|y)  \propto  \theta^{\alpha-1}\theta^{\sum y}e^{-\beta\theta} e^{-n\theta} \]\[  \propto \theta^{\alpha-1+\sum y}e^{-(\beta+n)\theta}  \]
Bu dagilim nedir? Formulun sag tarafi Gamma dagiliminin formulune
benzemiyor mu? Evet, formulun sag tarafi
$Gamma(\alpha+\sum y, \beta + n)$ dagilimi, yani ona orantili olan bir
formul. Yani Bayes teorisi uzerinden sunu anlamis olduk; eger oncul
dagilim Gamma ise, Poisson mumkunluk bizi tekrar Gamma sonuc dagilimina
goturuyor. Gamma'dan baslayinca tekrar Gamma'ya ulasiyoruz. Bu bir
rahatlik, bir kolaylik, bir matematiksel numara olarak kullanilabilir.
Sonuc (posterior) dagilimlarin sekli, hesaplanma, cebirsel islemler
acisindan onemli, eger temiz, kisa, oz olurlarsa hesap islerimiz
kolaylasir.

Not: Hatta uzerinde calistigimiz problem sebebiyle eger Poisson
mumkunluk olacagini biliyorsak, sadece bu sebeple bile oncul dagilimi,
ustteki kolaylik bilindigi icin, ozellikle Gamma secebiliriz, cunku
biliriz ki Gamma ile baslarsak elimize tekrar Gamma gececektir.

Simdi komur madeni verisine gelelim. Bu madendeki kazalarin sayisinin
Poisson dagilimindan geldigini one suruyoruz, ve kazalarin ``iki turlu''
oldugunu bildigimizden hareketle, birinci tur kazalarin ikinci tur
kazalardan degisik Poisson parametresi kullandigini one surecegiz.

O zaman degisim anini, degisim senesini nasil hesaplariz?

Kazalarin ilk k senede ortalama $\theta$ ile, ve k ve n arasindaki
senelerde ortalama $\lambda$ Poisson ile dagildigini soyleyelim: Yani
\[ Y_i = Poisson(\theta) \ \ \ i=1,..,k   \]\[ Y_i = Poisson(\lambda) \ \ \ i=k+1,..,n \]
Burada $Y_i$ sene i sirasinda olan kazalarin sayisini belirtiyor. Bayes
kuralini hatirlarsak $\theta$ ve $\lambda$ parametrelerine oncul dagilim
atayacagiz. Bu dagilim Gamma olacak. Yani $\theta \sim Gamma(a_1, b_1)$
ve $\lambda \sim Gamma(a_2, b_2)$.

Ayrica k degerini de bilmiyoruz, k degeri yani ``degisim noktasi''
Poisson dagilimlarin birinden otekine gectigi andir. Bu seneyi bulmaya
calisiyoruz. Simdi tum verinin, tum seneleri kapsayacak sekilde modelini
kurmaya baslayalim. k parametresinin aynen oteki parametreler gibi bir
oncul dagilimi olacak (ki sonradan elimize k icin de bir sonuc dagilimi
gececek), ama bu parametre elimizdeki 112 senenin herhangi birinde
``esit olasilikta'' olabilecegi icin onun oncul dagilimi Gamma degil
$k \sim Unif(1,112)$ olacak. Yani ilk basta her senenin olasiligi
birbiriyle esit, her sene $\frac{1}{112}$ olasilik degeri tasiyor.

Bu modelin tamaminin mumkunlugu nedir?
\[ L(\theta, \lambda, k | y) = \frac{1}{112} \times \displaystyle \prod_{i=1}^k
\frac{e^{-\theta}\theta^{y_i}}{y_i!}  \times \displaystyle \prod_{i=k+1}^n
\frac{e^{-\lambda}\lambda^{y_i}}{y_i!} 
 \] Eger sonuc (posterior) gecisini yapinca yukarida oldugu gibi Gamma
dagilimlarini elde ederiz:
\[ L(\theta, \lambda, k | y)  \propto 
\theta^{a_1-1+\sum_{i=1}^{k} y_i}e^{-(b_1+k)\theta} 
\lambda^{a_2-1+\sum_{i=k+1}^n y_i}e^{-(b_2+n-k)\lambda} 
 \]
$\frac{1}{112}$'yi bir sabit oldugu icin formulden attik, bu durum
orantili hali etkilemiyor. Ustteki formul icindeki Gamma dagilimlarini
gorebiliyoruz, hemen yerlerine koyalim:
\[ L(\theta, \lambda, k | y)  \propto 
Gamma(a_1 + \sum_{i=1}^{k} y_i, b_1+k) \
Gamma(a_2 + \sum_{i=k+1}^{n} y_i, b_2+n-k)
 \]
Gibbs orneklemeye gelelim. Bu orneklemeye gore sartsal dagilim
(conditional distribution) formulu bulunmaya ugrasilir, hangi
degiskenlerin verili olduguna gore, o degiskenler sabit kabul
edilebilir, ve orantisal formulden atilabilir. Bu her degisken icin
teker teker yapilir.

Sorna hesap sirasinda her sartsal dagilima teker teker zar attirilir, ve
elde edilen deger, bu sefer diger sartsal dagilimlara deger olarak
gecilir. Bu islem sonuca erisilinceye kadar ozyineli (iterative) olarak
tekrar edilir (mesela 1000 kere). O zaman,
\[ \theta | Y_1,..,Y_n,k \sim Gamma(a_1 + \sum_{i=1}^{k} y_i, b_1+k) \]\[ \lambda | Y_1,..,Y_n,k \sim Gamma(a_2 + \sum_{i=k+1}^{n} y_i, b_2+n-k) \]\[ 
p(k | Y_1,..,Y_n) \propto \theta^{\sum_{i=1}^{k} y_i}e^{-k\theta} 
\lambda^{\sum_{i=k+1}^n y_i}e^{k\lambda} 
 \]
En son formulde icinde k olan terimleri tuttuk, gerisini attik. Formul
$e$ terimleri birlestirilerek biraz daha basitlestirilebilir:
\[ p(k | Y_1,..,Y_n) \propto
\theta^{\sum_{i=1}^{k} y_i} \lambda^{\sum_{i=k+1}^n y_i}e^{(\lambda-\theta)k} 
 \]
Bir basitlestirme daha soyle olabilir
\[ K = \sum_{i=1}^{k} y_i  \]\[ \lambda^{\sum_{i=k+1}^n y_i} = \lambda^{\sum_{i=1}^n y_i - \sum_{i=1}^k y_i} \]
Ustel islemlerde eksi isareti, ustel degisken ayrilinca bolum islemine
donusur:
\[ = \frac{\lambda^{\sum_{i=1}^n y_i}}{\lambda ^{\sum_{i=1}^k y_i}} \]\[ = \frac{\lambda^{\sum_{i=1}^n y_i}}{\lambda ^{K}} \]\[ p(k | Y_1,..,Y_n) \propto 
\theta^{K} \frac{\lambda^{\sum_{i=1}^n y_i}}{\lambda ^{K}} e^{(\lambda-\theta)k} 
 \]\[ = \bigg(\frac{\theta}{\lambda}\bigg)^{K} \lambda^{\sum_{i=1}^n  y_i} e^{(\lambda-\theta)k} \]
$\lambda^{\sum_{i=1}^n y_i}$ terimi $k$'ye degil $n$'ye bagli oldugu
icin o da final formulden atilabilir
\[  
p(k | Y_1,..,Y_n) \propto \bigg(\frac{\theta}{\lambda}\bigg)^{K} 
e^{(\lambda-\theta)k}  
\]
$p(k)$ icin ortaya cikan bu formule bakarsak, elimizde verilen her k
degeri icin bir olasilik dondurecek bir formul var. Daha onceki Gamma
orneginde formule bakarak elimizde hemen bir Gamma dagilimi oldugunu
soyleyebilmistik. Bu kodlama sirasinda isimize yarayacak bir seydi,
hesaplama icin bir dagilima ``zar attirmamiz'' gerekiyor, ve Gamma
orneginde hemen Python Numpy kutuphanesindeki random.gamma cagrisina
Gamma'dan gelen rasgele sayilar urettirebiliriz. Ustteki formule
bakarsak, hangi dagilima zar attiracagiz?

Cevap soyle: $p(k|..)$ pdf fonsiyonundaki k degiskeni $1,..,119$
arasindaki tam sayi degerleri alabilir, o zaman ortada bir ayriksal
(discrete) dagilim var demektir. Ve her k noktasi icin olabilecek
olasilik degerini ustteki $p(k|..)$ formulune hesaplattirabiliyorsak,
ayriksal bir dagilimi her nokta icin ustteki cagri, ve bu sonuclari
normalize ederek (vektorun her elemanini vektorun toplamina bolerek) bir
dagilim sekline donusturebiliriz. Daha sonra bu ``vektorsel dagilim''
uzerinden zar attiririz. Python kodundaki \verb!w_choice! ya da R
dilindeki \verb!sample! cagrisi bu isi yapar.

Kodlari isletince elimize k = 41 degeri gececek, yani degisim ani
1851+41 = 1892 senesidir (zar attirmaya gore sonuc bazen 40, bazen 42 de
olabilir).

\begin{codecell}
\begin{codeinput}
\begin{lstlisting}
import math
import random

# samples indexes from a sequence of probability table
# based on those probabilities
def w_choice(lst):
    n = random.uniform(0, 1)
    for item, weight in enumerate(lst):
        if n < weight:
            break
        n = n - weight
    return item

#
# hyperparameters: a1, a2, b1, b2
#
def coal(n,x,init,a1,a2,b1,b2):
    nn=len(x)
    theta=init[0]
    lam=init[1]
    k = init[2]
    z=np.zeros((nn,))
    for i in range(n):
        ca = a1 + sum(x[0:k])
        theta = np.random.gamma(ca, 1/float(k + b1), 1) 
        ca = a2 + sum(x[(k+1):nn])
        lam = np.random.gamma(ca, 1/float(nn-k + b2), 1)
        for j in range(nn):
            z[j]=math.exp((lam-theta)*(j+1)) * (theta/lam)**sum(x[0:j])
        # sample
        zz = z / sum(z)
        k = w_choice(zz)
    print float(theta), float(lam), float(k)
                
data = np.loadtxt("coal.txt")
coal(1100, data, init=[1,1,30], a1=1,a2=1,b1=1,b2=1)

\end{lstlisting}
\end{codeinput}
\begin{codeoutput}
\begin{verbatim}
2.67481325587 0.743331307925 42.0
\end{verbatim}
\end{codeoutput}
\end{codecell}
Kaynaklar:

Ioana A. Cosma and Ludger Evers, Markov Chain Monte Carlo Methods
(Lecture)

Charles H. Franklin, Bayesian Models for Social Science Analysis
(Lecture)

\end{document}
