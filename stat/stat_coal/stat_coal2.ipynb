{
 "metadata": {
  "name": "stat_coal2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "source": [
      "MCMC, Degisim Nokta Hesabi, Gibbs Orneklemesi, Bayes Teorisi\n",
      "\n",
      "Ingiltere'de 1851 ve 1962 yillari arasinda komur madenlerinde olan\n",
      "kazalarin sayisi yillik olarak kayitli . Acaba bu kazalarin\n",
      "\"oraninin\" degisimine bakarak, degisimin oldugu seneyi bulabilir\n",
      "miyiz? Boyle bir degisim ani neyi gosterir? Belki madenlerle alakali\n",
      "regulasyonlarda, denetimlerde bir degisiklik olmustur, ve kaza orani\n",
      "azalmistir.\n",
      "\n",
      "Bu hesabi yapabilmek icin \"degisim noktasi\" hesabi (change-point\n",
      "analysis), ve Bayes kurali ile Bayes formullerini hesaplamamizi\n",
      "saglayan Markov Chain Monte Carlo (MCMC) teknigine\n",
      "bakacagiz. Kazalarin sayisinin tumunu iki Poisson dagiliminin\n",
      "ortak dagilimi (joint distribution) uzerinden modelleyecegiz, ve bu\n",
      "dagilimlarin birinci Poisson'dan ikincisine gectigi ani hesaplamaya\n",
      "ugrasacagiz.\n",
      "\n",
      "Once Bayes, dagilimlar konusuna bir bakalim:\n",
      "\n",
      "Poisson dagilimi\n",
      "\n",
      "$$ p(y|\\theta) = \\frac{e^{-\\theta}\\theta^y}{y!} $$\n",
      "\n",
      "Eldeki n tane veri noktasi $y=y_0, y_1,...,y_n$'nin hep birlikte\n",
      "$\\theta$ ile tanimli bir Poisson dagilimindan gelip gelmediginin ne\n",
      "kadar mumkun oldugu (likelihood) hesabi soyledir:\n",
      "\n",
      "$$ p(y|\\theta) = \\frac{e^{-n\\theta}\\theta^{\\sum y_i}}{\\prod y_i!}  $$\n",
      "\n",
      "Formulun bolunen kismindaki tum y noktalari toplaniyor, bolen kisminde\n",
      "ise tum y degerleri teker teker faktoryel hesabi sonrasi birbiri ile\n",
      "carpiliyor.\n",
      "\n",
      "Simdi yukaridaki $\\theta$ degiskeni de noktasal bir deger yerine bir\n",
      "\"dagilima\", mesela $\\theta$ Gamma dagilimina sahip olabilirdi:\n",
      "$Gamma(\\alpha, \\beta)$. Formulde $\\alpha$, $\\beta$ sabit degerlerdir\n",
      "(fonksiyon degiskeni degil). Gamma olasilik formulu soyledir:\n",
      "\n",
      "$$ p(\\theta) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)}\\theta^{\\alpha-1}e^{-\\beta\\theta} $$\n",
      "\n",
      "O zaman $p(y|\\theta)$ formulunu bulmak icin Bayes teorisini\n",
      "kullanmamiz gerekecekti. Bayes teorisi bilindigi gibi\n",
      "\n",
      "$$ p(\\theta|y) = \\frac{p(y|\\theta)p(\\theta)}{p(y)} $$\n",
      "\n",
      "$$ p(\\theta|y) \\propto p(y|\\theta)p(\\theta) $$\n",
      "\n",
      "Ikinci formule dikkat, esitlik yerine orantili olma (proportional to)\n",
      "isaretini kullaniyor. Sebep: bolen kismindaki p(y)'yi kaldirdik, sonuc\n",
      "olarak soldaki $p(\\theta|y)$ degeri artik bir dagilim degil -- bu bir\n",
      "bakimdan onemli ama ornekleme amaci icin bir fark yaratmiyor,\n",
      "basitlestirme amaciyla bunu yaptik, boylece $p(y)$'yi hesaplamamiz\n",
      "gerekmeyecek, ama ornekleme uzerinden diger tum hesaplari hala\n",
      "yapabiliriz. Tamam.\n",
      "\n",
      "Simdi Bayes Teorisini Gamma oncul (apriori) ve Poisson mumkunlugu\n",
      "(likelihood) uzerinden kullanirsak,\n",
      "\n",
      "$$ \n",
      "p(\\theta|y) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)}\n",
      "\\theta^{\\alpha-1}e^{-\\beta\\theta} \\times\n",
      "\\frac{e^{-n\\theta}\\theta^{\\sum y}}{\\prod y!} \n",
      "$$\n",
      "\n",
      "Benzer terimleri yanyana getirelim:\n",
      "\n",
      "$$ \n",
      "p(\\theta|y) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)\\prod y!}\n",
      "\\theta^{\\alpha-1}\\theta^{\\sum y}e^{-\\beta\\theta} e^{-n\\theta} \n",
      "$$\n",
      "\n",
      "Simdi sol taraftaki bolumu atalim; yine usttekine benzer numara, bu\n",
      "kisim gidince geri galan dagilim olamayacak, ama ona \"oranli\" baska\n",
      "bir formul olacak.\n",
      "\n",
      "$$ p(\\theta|y)  \\propto  \\theta^{\\alpha-1}\\theta^{\\sum y}e^{-\\beta\\theta} e^{-n\\theta} $$\n",
      "\n",
      "$$  \\propto \\theta^{\\alpha-1+\\sum y}e^{-(\\beta+n)\\theta}  $$\n",
      "\n",
      "Bu dagilim nedir? Formulun sag tarafi Gamma dagiliminin formulune\n",
      "benzemiyor mu?  Evet, formulun sag tarafi $Gamma(\\alpha+\\sum y, \\beta\n",
      "+ n)$ dagilimi, yani ona orantili olan bir formul. Yani Bayes teorisi\n",
      "uzerinden sunu anlamis olduk; eger oncul dagilim Gamma ise, Poisson\n",
      "mumkunluk bizi tekrar Gamma sonuc dagilimina goturuyor. Gamma'dan\n",
      "baslayinca tekrar Gamma'ya ulasiyoruz. Bu bir rahatlik, bir kolaylik,\n",
      "bir matematiksel numara olarak kullanilabilir. Sonuc (posterior)\n",
      "dagilimlarin sekli, hesaplanma, cebirsel islemler acisindan onemli,\n",
      "eger temiz, kisa, oz olurlarsa hesap islerimiz kolaylasir.\n",
      "\n",
      "Not: Hatta uzerinde calistigimiz problem sebebiyle eger Poisson\n",
      "mumkunluk olacagini biliyorsak, sadece bu sebeple bile oncul dagilimi,\n",
      "ustteki kolaylik bilindigi icin, ozellikle Gamma secebiliriz, cunku\n",
      "biliriz ki Gamma ile baslarsak elimize tekrar Gamma gececektir.\n",
      "\n",
      "Simdi komur madeni verisine gelelim. Bu madendeki kazalarin sayisinin\n",
      "Poisson dagilimindan geldigini one suruyoruz, ve kazalarin \"iki turlu\"\n",
      "oldugunu bildigimizden hareketle, birinci tur kazalarin ikinci tur\n",
      "kazalardan degisik Poisson parametresi kullandigini one surecegiz.\n",
      "\n",
      "O zaman degisim anini, degisim senesini nasil hesaplariz?\n",
      "\n",
      "Kazalarin ilk k senede ortalama $\\theta$ ile, ve k ve n arasindaki\n",
      "senelerde ortalama $\\lambda$ Poisson ile dagildigini soyleyelim: Yani\n",
      "\n",
      "$$ Y_i = Poisson(\\theta) \\ \\ \\ i=1,..,k   $$\n",
      "\n",
      "$$ Y_i = Poisson(\\lambda) \\ \\ \\ i=k+1,..,n $$\n",
      "\n",
      "Burada $Y_i$ sene i sirasinda olan kazalarin sayisini belirtiyor. Bayes kuralini\n",
      "hatirlarsak $\\theta$ ve $\\lambda$ parametrelerine oncul dagilim atayacagiz. Bu\n",
      "dagilim Gamma olacak. Yani $\\theta \\sim Gamma(a_1, b_1)$ ve $\\lambda \\sim\n",
      "Gamma(a_2, b_2)$.\n",
      "\n",
      "Ayrica k degerini de bilmiyoruz, k degeri yani \"degisim noktasi\" Poisson\n",
      "dagilimlarin birinden otekine gectigi andir. Bu seneyi bulmaya\n",
      "calisiyoruz. Simdi tum verinin, tum seneleri kapsayacak sekilde modelini kurmaya\n",
      "baslayalim. k parametresinin aynen oteki parametreler gibi bir oncul dagilimi\n",
      "olacak (ki sonradan elimize k icin de bir sonuc dagilimi gececek), ama bu\n",
      "parametre elimizdeki 112 senenin herhangi birinde \"esit olasilikta\" olabilecegi\n",
      "icin onun oncul dagilimi Gamma degil $k \\sim Unif(1,112)$ olacak. Yani ilk basta\n",
      "her senenin olasiligi birbiriyle esit, her sene $\\frac{1}{112}$ olasilik degeri\n",
      "tasiyor.\n",
      "\n",
      "Bu modelin tamaminin mumkunlugu nedir?\n",
      "\n",
      "$$ L(\\theta, \\lambda, k | y) = \\frac{1}{112} \\times \\displaystyle \\prod_{i=1}^k\n",
      "\\frac{e^{-\\theta}\\theta^{y_i}}{y_i!}  \\times \\displaystyle \\prod_{i=k+1}^n\n",
      "\\frac{e^{-\\lambda}\\lambda^{y_i}}{y_i!} \n",
      " $$\n",
      "Eger sonuc (posterior) gecisini yapinca yukarida oldugu gibi Gamma dagilimlarini\n",
      "elde ederiz:\n",
      "\n",
      "$$ L(\\theta, \\lambda, k | y)  \\propto \n",
      "\\theta^{a_1-1+\\sum_{i=1}^{k} y_i}e^{-(b_1+k)\\theta} \n",
      "\\lambda^{a_2-1+\\sum_{i=k+1}^n y_i}e^{-(b_2+n-k)\\lambda} \n",
      " $$\n",
      "\n",
      "$\\frac{1}{112}$'yi bir sabit oldugu icin formulden attik, bu durum orantili hali\n",
      "etkilemiyor. Ustteki formul icindeki Gamma dagilimlarini gorebiliyoruz, hemen\n",
      "yerlerine koyalim:\n",
      "\n",
      "$$ L(\\theta, \\lambda, k | y)  \\propto \n",
      "Gamma(a_1 + \\sum_{i=1}^{k} y_i, b_1+k) \\\n",
      "Gamma(a_2 + \\sum_{i=k+1}^{n} y_i, b_2+n-k)\n",
      " $$\n",
      "\n",
      "Gibbs orneklemeye gelelim. Bu orneklemeye gore sartsal dagilim (conditional\n",
      "distribution) formulu bulunmaya ugrasilir, hangi degiskenlerin verili olduguna\n",
      "gore, o degiskenler sabit kabul edilebilir, ve orantisal formulden\n",
      "atilabilir. Bu her degisken icin teker teker yapilir. \n",
      "\n",
      "Sorna hesap sirasinda her sartsal dagilima teker teker zar attirilir, ve elde\n",
      "edilen deger, bu sefer diger sartsal dagilimlara deger olarak gecilir. Bu islem\n",
      "sonuca erisilinceye kadar ozyineli (iterative) olarak tekrar edilir (mesela 1000\n",
      "kere). O zaman,\n",
      "\n",
      "$$ \\theta | Y_1,..,Y_n,k \\sim Gamma(a_1 + \\sum_{i=1}^{k} y_i, b_1+k) $$\n",
      "\n",
      "$$ \\lambda | Y_1,..,Y_n,k \\sim Gamma(a_2 + \\sum_{i=k+1}^{n} y_i, b_2+n-k) $$\n",
      "\n",
      "$$ \n",
      "p(k | Y_1,..,Y_n) \\propto \\theta^{\\sum_{i=1}^{k} y_i}e^{-k\\theta} \n",
      "\\lambda^{\\sum_{i=k+1}^n y_i}e^{k\\lambda} \n",
      " $$\n",
      "\n",
      "En son formulde icinde k olan terimleri tuttuk, gerisini attik. Formul $e$\n",
      "terimleri birlestirilerek biraz daha basitlestirilebilir:\n",
      "\n",
      "$$ p(k | Y_1,..,Y_n) \\propto\n",
      "\\theta^{\\sum_{i=1}^{k} y_i} \\lambda^{\\sum_{i=k+1}^n y_i}e^{(\\lambda-\\theta)k} \n",
      " $$\n",
      "\n",
      "Bir basitlestirme daha soyle olabilir\n",
      "\n",
      "$$ K = \\sum_{i=1}^{k} y_i  $$\n",
      "\n",
      "$$ \\lambda^{\\sum_{i=k+1}^n y_i} = \\lambda^{\\sum_{i=1}^n y_i - \\sum_{i=1}^k y_i} $$\n",
      "\n",
      "Ustel islemlerde eksi isareti, ustel degisken ayrilinca bolum islemine donusur:\n",
      "\n",
      "$$ = \\frac{\\lambda^{\\sum_{i=1}^n y_i}}{\\lambda ^{\\sum_{i=1}^k y_i}} $$\n",
      "\n",
      "$$ = \\frac{\\lambda^{\\sum_{i=1}^n y_i}}{\\lambda ^{K}} $$\n",
      "\n",
      "$$ p(k | Y_1,..,Y_n) \\propto \n",
      "\\theta^{K} \\frac{\\lambda^{\\sum_{i=1}^n y_i}}{\\lambda ^{K}} e^{(\\lambda-\\theta)k} \n",
      " $$\n",
      "\n",
      "$$ = \\bigg(\\frac{\\theta}{\\lambda}\\bigg)^{K} \\lambda^{\\sum_{i=1}^n  y_i} e^{(\\lambda-\\theta)k} $$\n",
      "\n",
      "$\\lambda^{\\sum_{i=1}^n y_i}$ terimi $k$'ye degil $n$'ye bagli oldugu\n",
      "icin o da final formulden atilabilir\n",
      "\n",
      "$$  \n",
      "p(k | Y_1,..,Y_n) \\propto \\bigg(\\frac{\\theta}{\\lambda}\\bigg)^{K} \n",
      "e^{(\\lambda-\\theta)k}  \n",
      "$$  \n",
      "\n",
      "$p(k)$ icin ortaya cikan bu formule bakarsak, elimizde verilen her k\n",
      "degeri icin bir olasilik dondurecek bir formul var. Daha onceki Gamma\n",
      "orneginde formule bakarak elimizde hemen bir Gamma dagilimi oldugunu\n",
      "soyleyebilmistik. Bu kodlama sirasinda isimize yarayacak bir seydi,\n",
      "hesaplama icin bir dagilima \"zar attirmamiz\" gerekiyor, ve Gamma\n",
      "orneginde hemen Python Numpy kutuphanesindeki random.gamma cagrisina\n",
      "Gamma'dan gelen rasgele sayilar urettirebiliriz. Ustteki formule\n",
      "bakarsak, hangi dagilima zar attiracagiz?\n",
      "\n",
      "Cevap soyle: $p(k|..)$ pdf fonsiyonundaki k degiskeni $1,..,119$ arasindaki\n",
      "tam sayi degerleri alabilir, o zaman ortada bir ayriksal (discrete) dagilim\n",
      "var demektir. Ve her k noktasi icin olabilecek olasilik degerini ustteki\n",
      "$p(k|..)$ formulune hesaplattirabiliyorsak, ayriksal bir dagilimi her nokta\n",
      "icin ustteki cagri, ve bu sonuclari normalize ederek (vektorun her\n",
      "elemanini vektorun toplamina bolerek) bir dagilim sekline\n",
      "donusturebiliriz. Daha sonra bu \"vektorsel dagilim\" uzerinden zar\n",
      "attiririz. Python kodundaki \\verb!w_choice! ya da R dilindeki \\verb!sample!\n",
      "cagrisi bu isi yapar.\n",
      "\n",
      "Kodlari isletince elimize k = 41 degeri gececek, yani degisim ani\n",
      "1851+41 = 1892 senesidir (zar attirmaya gore sonuc bazen 40, bazen 42\n",
      "de olabilir).\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "import random\n",
      "\n",
      "# samples indexes from a sequence of probability table\n",
      "# based on those probabilities\n",
      "def w_choice(lst):\n",
      "    n = random.uniform(0, 1)\n",
      "    for item, weight in enumerate(lst):\n",
      "        if n < weight:\n",
      "            break\n",
      "        n = n - weight\n",
      "    return item\n",
      "\n",
      "#\n",
      "# hyperparameters: a1, a2, b1, b2\n",
      "#\n",
      "def coal(n,x,init,a1,a2,b1,b2):\n",
      "    nn=len(x)\n",
      "    theta=init[0]\n",
      "    lam=init[1]\n",
      "    k = init[2]\n",
      "    z=np.zeros((nn,))\n",
      "    for i in range(n):\n",
      "        ca = a1 + sum(x[0:k])\n",
      "        theta = np.random.gamma(ca, 1/float(k + b1), 1) \n",
      "        ca = a2 + sum(x[(k+1):nn])\n",
      "        lam = np.random.gamma(ca, 1/float(nn-k + b2), 1)\n",
      "        for j in range(nn):\n",
      "            z[j]=math.exp((lam-theta)*(j+1)) * (theta/lam)**sum(x[0:j])\n",
      "        # sample\n",
      "        zz = z / sum(z)\n",
      "        k = w_choice(zz)\n",
      "    print float(theta), float(lam), float(k)\n",
      "                \n",
      "data = np.loadtxt(\"coal.txt\")\n",
      "coal(1100, data, init=[1,1,30], a1=1,a2=1,b1=1,b2=1)\n"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2.67481325587 0.743331307925 42.0\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "source": [
      "Kaynaklar: \n",
      "\n",
      "Ioana A. Cosma and Ludger Evers, Markov Chain Monte Carlo Methods (Lecture) \n",
      "\n",
      "Charles H. Franklin, Bayesian Models for Social Science Analysis (Lecture)\n"
     ]
    }
   ]
  }
 ]
}