\documentclass[12pt,fleqn]{article}\usepackage{../common}
\begin{document}
Ders 6

Moment Fonksiyonlari

Olasýlýk matematiðinde "moment üreten iþlevler" olarak adlandýrýlan,
baþlangýçta pek yararlý gibi gözükmesede bir takým matematiksel
özellikleri olduðu için, ispatlarda oldukça iþe yarayan bir kavram
vardýr.

Her rasgele deðiþkenin bir daðýlýmý olduðunu biliyoruz. Her rasgele
deðiþkenin de ayrýca bir moment üreten fonksiyonu da vardýr. Ayrýca,
moment üreten fonksiyon ile rasgele deðiþken arasýnda bire-bir olarak
bir iliþki mevcuttur. "Bu neye yarar?" diye sorulabilir; Cevap olarak,
mesela cebirsel olarak türete türete bir moment'e geldiðimiz
düþünelim, ve tekrar baþka bir taraftan, baþka bir formülden gene
türete türete tekrar ayný moment iþlevine geliyorsak, bu demektir ki,
iki taraftan gelen rasgele deðiþkenler (ve tekabül eden daðýlýmlarý)
birbirine eþittir. Bazý þartlarda moment üreten iþlevler ile cebir
yapmak, daðýlým fonksiyonlarýndan daha rahat olmaktadýr.

Her rasgele deðiþken için, moment üreten iþlev þöyle bulunur.

$X$ rasgele degiskenin moment ureten operasyonu

$M(t)=E(e^{tX})$ olarak gosterilir

Ayriksal operasyonlar icin

\[ M(t) = \sum_x e^{tx}p(x) \]

Surekli islevler icin

\[ M(t) = \int_{-\infty}^{\infty} e^{tx}f(x)dx   \]

Kuram

Gelelim yazýmýzýn esas konusu olan kuramýmýza.

Eðer $X_1, X_2...X_n$ baðýmsýz rasgele deðiþken ise, ve her deðiþkenin
$M_i(t)$ $i=1,2,3,...n$ olarak, öz olarak ayný olan birer moment üreten
iþlevi var ise, o zaman,

\[ Y = \sum_{i=1}^n  aX_i \]

acilimi

\[ M_y(t) = \prod_{i=1}^n M(a_i t) \]

olacaktir. 

Ispat

\[ M_y(t) = E(e^{tY}=E(e^{t(a_1X_1+a_2X_2+..+a_nX_n)} \]

\[ = E[\exp(ta_1 X_1 ta_2X_2...+ta_nX_n)] \]

\[ = E[\exp(ta_1X_1)+\exp(ta_2X_2)+ ... + \exp(ta_nX_n)] \]

\[ = E[\exp(ta_1X_1)]+E[\exp(ta_2X_2)]+ ... + E[\exp(ta_nX_n)]\]

Daha once belirttigimiz gibi

\[ M_i(t) = E[\exp(tX_i)] \]

olduguna gore ve $t$ yerine $ta_i$ koyuldugunu dusunelim

\[ M_y(t) = \prod_{i=1}^n M_y(a_it) \]

olacaktir. 

Bunu $M_y(t)= (M_i(a_it))^n$ seklinde de gosterebiliriz. 

Orneklem Dagilimlari (Sampling Distributions)

Diyelim ki elimizde (hakkinda) ogrenmek istedigimiz bir sayisal obek
(population) var. Bu obekteki her elemani ayri ayri incelemek
istemiyoruz, problem degil, nufustan bir orneklem (sample) aliriz.
Eger bu orneklem nufusu yeterince iyi temsil ediyorsa, problem cikmaz.
Bu temsiliyeti garantilemenin iyi bir yolu orneklemi rasgele yapmaktir.

Simdi, diyelim ki, bu orneklemi bir sekilde ozetlemek istiyoruz yani
orneklem verisi kullanilarak hesaplanmis temsili bir istatistik
(descriptive statistic) elde edecegiz.

Fakat orneklemimiz rasgele idi. Bu istatistigimiz (ki o da sonucta bir
rasgele degiskendir ve onun da bir dagilimi vardir), nasil bir
dagilima sahiptir? Yani nufus dagilimi (population distribution), ve
orneklem dagiliminin (sampling distribution) birbiriyle
baglantisiyla ilgileniyoruz.

Teori

Eger $X_1,..,X_n$ bir $N(\mu,\sigma)$ dagiliminda alinmis orneklem olsun.
O zaman orneklem ortalamasinin dagilimi $N(\mu,\sigma/\sqrt{n})$. 

[TBD - Ispat]

Teori

Eger $X_1,..,X_n$ bir $N(\mu,\sigma)$ dagiliminda alinmis orneklem olsun.
O zaman su buyukluk

$$ T = \frac{ \bar{X}-\mu}{S / \sqrt{n}} $$

$t_{n-1}$ dagilimina, yani $n-1$ serbestlik derecesindeki (degree of
freedom) bir Student's t Dagilimidir.

[TBD - Ispat]

Hipotez Testleri (Hypothesis Testing)

Hipotez testi (bir veriye dayanarak) farzedilen bir parametreyi bir
sabit degerle karsilastirmak, ya da iki parametreyi birbiriyle
karsilastirmak icin kullanilir. 

Bir hipotez testi, sonucta sadece iki cevap verebilecek bir sorudur;
bu sonuclar "reddetmek" ya da "reddetmemek" olabilir. Dikkat: bu
sonuclardan biri "kabul etmek" degil, bir istatistiki hipotezi kabul
etmek mumkun degildir. Tek soyleyebildigimiz "bir hipotezi reddetmek
icin elimizde yeterli veri olmadigini" soylemektir. Ama
reddedebiliyorsak, bu sonucta daha bir kesinlik vardir. 

Tek Orneklem t Testi (One-sample t test)

Bu test verinin Normal dagilimdan geldigini farzeder, tek orneklem
durumunda elde $x_1,...,x_n$ verisi vardir, ve bu veri $N(\mu,\Sigma)$
dagilimindan gelmistir ve test etmek istedigimiz hipotez /
karsilastirma $\mu = \mu_0$. 

\begin{minted}[fontsize=\footnotesize]{python}
from scipy.stats import ttest_1samp, wilcoxon, ttest_ind
import pandas as pd
daily_intake = np.array([5260,5470,5640,6180,6390,6515, 6805,7515,7515,8230,8770])
df = pd.DataFrame(daily_intake)
print df.describe()
\end{minted}

\begin{verbatim}
                 0
count    11.000000
mean   6753.636364
std    1142.123222
min    5260.000000
25%    5910.000000
50%    6515.000000
75%    7515.000000
max    8770.000000
\end{verbatim}

\begin{minted}[fontsize=\footnotesize]{python}
t_statistic, p_value = ttest_1samp(daily_intake, 7725)
print "one-sample t-test", p_value
\end{minted}

\begin{verbatim}
one-sample t-test 0.0181372351761
\end{verbatim}

Sonuc \verb!p_value! \verb!0.05!'ten kucuk cikti yani
yuzde 5 onemliligini (significance) baz aldik bu durumda veri
hipotezden onemli derecede (significantly) uzakta. Demek ki
ortalamanin 7725 oldugu hipotezini reddetmemiz gerekiyor.

Testi iki orneklemli kullanalim, gruplar 0/1 degerleri ile
isaretlendi, ve test etmek istedigimiz iki grubun ortalamasinin (mean)
ayni oldugu hipotezini test etmek. t-test bu arada varyansin ayni
oldugunu farzeder.

\begin{minted}[fontsize=\footnotesize]{python}
energ = np.array([
[9.21, 0],
[7.53, 1],
[7.48, 1],
[8.08, 1],
[8.09, 1],
[10.15, 1],
[8.40, 1],
[10.88, 1],
[6.13, 1],
[7.90, 1],
[11.51, 0],
[12.79, 0],
[7.05, 1],
[11.85, 0],
[9.97, 0],
[7.48, 1],
[8.79, 0],
[9.69, 0],
[9.68, 0],
[7.58, 1],
[9.19, 0],
[8.11, 1]])
group1 = energ[energ[:, 1] == 0][:, 0]
group2 = energ[energ[:, 1] == 1][:, 0]
t_statistic, p_value = ttest_ind(group1, group2)
print "two-sample t-test", p_value
\end{minted}

\begin{verbatim}
two-sample t-test 0.00079899821117
\end{verbatim}

$p-value < 0.05$ yani iki grubun ortalamasi ayni degildir. Ayni oldugu
hipotezi reddedildi.

Eslemeli t-Test (Paired t-test)

Eslemeli testler ayni deneysel birimin olcumu alindigi zaman
kullanilabilir, yani olcum alinan ayni grupta, deney sonrasi deneyin
etki edip etmedigi test edilebilir. Bunun icin ayni olcum deney
sonrasi bir daha alinir ve "farklarin ortalamasinin sifir oldugu"
hipotezi test edilebilir. Altta bir grup hastanin deney oncesi ve
sonrasi ne kadar yiyecek tukettigi listelenmis. 

\begin{minted}[fontsize=\footnotesize]{python}
intake = np.array([
[5260, 3910],
[5470, 4220],
[5640, 3885],
[6180, 5160],
[6390, 5645],
[6515, 4680],
[6805, 5265],
[7515, 5975],
[7515, 6790],
[8230, 6900],
[8770, 7335],
])
pre = intake[:, 0]
post = intake[:, 1]
t_statistic, p_value = ttest_1samp(post - pre, 0)
print "paired t-test", p_value
\end{minted}

\begin{verbatim}
paired t-test 3.05902094293e-07
\end{verbatim}

Wilcoxon isaretli-sirali testi (Wilcoxon signed-rank test)

t Testleri Normal dagilima gore sapmalari yakalamak acisindan,
ozellikle buyuk orneklemler var ise, oldukca saglamdir. Fakat bazen
verinin Normal dagilimdan geldigi faraziyesini yapmak istemeyebiliriz.
Bu durumda {\em dagilimdan bagimsiz metotlar} daha uygundur, bu tur
metotlar icin verinin yerine cogunlukla onun sira istatistiklerini
(order statistics) kullanir.

Tek orneklemli Wilcoxon testi icin prosedur $\mu_0$'i tum veriden
cikartmak ve geri kalan (farklari) isaretine bakmadan numerik degerine
gore siralamak, ve bu sira degerini bir kenara yazmak. Daha sonra geri
donup bu sefer cikartma islemi sonucunun isaretine bakmak, ve eksi
isareti tasiyan sira degerlerini toplamak, ayni islemi arti isareti
icin yapmak, ve eksi toplami arti toplamindan cikartmak. Sonucta
elimize bir istatistik $W$ gelecek. Bu test istatistigi aslinda $1..n$
tane sayi icinden herhangi birini $1/2$ olasiligiyla secmek, ve
sonuclari toplamaya tekabul etmektedir. Ve bu sonuc yine \verb!0.05!
ile karsilastirilir.

\begin{minted}[fontsize=\footnotesize]{python}
z_statistic, p_value = wilcoxon(daily_intake - 7725)
print "one-sample wilcoxon-test", p_value
\end{minted}

\begin{verbatim}
one-sample wilcoxon-test 0.0279991628713
\end{verbatim}

Hipotezi yine reddettik.

Ustte yaptigimiz eslemeli t-testi simdi Wilcoxon testi ile yapalim,

\begin{minted}[fontsize=\footnotesize]{python}
z_statistic, p_value = wilcoxon(post - pre)
print "paired wilcoxon-test", p_value
\end{minted}

\begin{verbatim}
paired wilcoxon-test 0.00463608893545
\end{verbatim}

Binom Testi

Binom dagilimi belli sayida "deney" icinde her seferinde $p$ olasiligi
tasiyan iki kategorili bir olaydan {\em kac tane} olabilecegini
modeller. Dagilim

$$
P(K = k) = \left( \begin{array}{ccc}
n \\ k
\end{array} \right)
p^k q^{n-k}
$$

olarak belirtilir, ki $q = 1-p$ degeridir. Bu dagilimin $n>20$, yani
"yeterince buyuk" degerleri icin Normal (Gaussian) Dagilima yaklastigi
/ onun gibi oldugu bilinmektedir. Bu yaklasilan dagilim ortalamasi
$np$ ve standart sapmasi $\sqrt{npq}$ olan bir Normal dagilim olacaktir, yani
$N(np,\sqrt{npq})$.

Devam edelim, madem elimizde bir normal dagilim var, bu normal dagilimi diger
her normal dagilim gibi standardize edebiliriz,

$$
Z = \frac{ K - np}{\sqrt{npq}} \sim N_{0,1}
$$

Burada rasgele degisken $K$, yani her binom deneyi ardindan ele
gececek basari sayisi burada. Binom testi icin test etmek istedigimiz
sey budur.  O zaman $p$ yerine test ettigimiz ana binom dagilimindan
gelen ana orani $\hat{p}$ kullaniriz, ki bu basari / tum deney sayisi
olarak hesaplanir, $K$ yeni deneydeki ele gecen basari sayisidir, n
ornekleminin buyuklugudur, bu sayilari yerine koyarak $Z$ dagilimindan
bir guven rakami (confidence) elde edebiliriz.

Bir ornek uzerinde gorelim: diyelim ki elimizde bir Web sitesinin
gunluk ziyaret, tiklama sayilarini gosteren bir veri seti var (CVR
ziyaretcilerin, sitedeki tiklayan musteriye "cevirme' orani,
-conversion-)

\begin{minted}[fontsize=\footnotesize]{python}
import pandas as pd
from scipy import stats
a = pd.DataFrame({'tiklama': [20.,2.,40.,5.,10.,100.],
                  'ziyaret': [100.,10.,300.,400.,30.,800.]})
a['cvr'] = a['tiklama'] / a['ziyaret'] 
print a
\end{minted}

\begin{verbatim}
   tiklama  ziyaret       cvr
0       20      100  0.200000
1        2       10  0.200000
2       40      300  0.133333
3        5      400  0.012500
4       10       30  0.333333
5      100      800  0.125000
\end{verbatim}

Diyelim ki bu veri seti icin cvr'in 0.16, yani yuzde 16 oldugunu
onceden biliyoruz. Ustteki basari orani binom dagili ile
modellenebilir, ziyaretler "deneylerdir", yani orneklem buyuklugunu
gosterirler. Tiklama ise basaridir,

\begin{minted}[fontsize=\footnotesize]{python}
p_hat = 0.16
btest = lambda x: (x['cvr']-p_hat) / np.sqrt( p_hat*(1-p_hat)/x['ziyaret'])
a['guven'] = a.apply(btest, axis=1)
a['guven'] = np.round(stats.zprob(a['guven'])*100,2)
print a
\end{minted}

\begin{verbatim}
   tiklama  ziyaret       cvr  guven
0       20      100  0.200000  86.24
1        2       10  0.200000  63.50
2       40      300  0.133333  10.39
3        5      400  0.012500   0.00
4       10       30  0.333333  99.52
5      100      800  0.125000   0.35
\end{verbatim}

Büyük Sayýlar Kanunu

Olasýlýk kuramýnda önemli matematiksel bir denklem, büyük sayýlar
kanunudur. Bu kanun, tahmini olarak bildiðimiz günlük bir gerçeðin
matematiksel ispatýdýr da denebilir.

Yazý-tura atarken yazý çýkma ihtimalinin 1/2 olduðunu biliyoruz. Herhalde
çoðumuz da bu yazý-tura iþleminin "bir çok kere" tekrarlandýðý durumda,
toplam sonucun aþaðý yukarý "yarýsýnýn" yazý olacaðýný tahmin biliyoruz. Bu
tahminin matematiksel olarak söylemi, büyük sayýlar kanunudur. Yýllarca
önce Öklid'in geometriyi ispat ederek yaptýðý gibi, matematiðe eklediðimizi
her yeni bilgi daðarcýðýný önce matematiksel olarak ispatlamamýz gerekiyor.

Farzedelim ki her yazý-tura atýþý bir deney olsun. Her ayrý deneyin sonucu
$X_1, X_2...X_n$ olarak rasgelen deðiþkenlerle tanýmlanmýþ olsun. Bu
deðiþkenler ya 1 ya da 0 deðeri taþýyacak, Yazý=1, Tura=0 olmak üzere.

Buna göre, n tane deneyden sonra elimize gelmesi gereken yazý oraný þudur.

\[ \bar{X_n} = \frac{1}{n} \sum_{i=1}^n X_i  \]

Büyük sayýlar kanunu, $n$ büyüdükçe $X_n$'in 1/2'ye yaklaþtýðýný ispatlar.

Baþlayalým.

$X_1,X_2,..,X_n$ bagimsiz degiskenler olsun. 

\[ E(X_i) = \mu \]

\[ Var(X_i) = \sigma \]

\[ \bar{X_n} = \frac{1}{n} \sum_{i=1}^n X_i  \]

O zaman her $\epsilon > 0$ icin ve $n \rightarrow \infty $, $p(|\bar{X_n} -
\mu|) \rightarrow 0$. 

Bu tanýmlara göre, her rasgele deðiþkenin (deneyin) ortalamasý ayni
deðerdir diyoruz. Bu zaten beklenir bir tanýmdý, çünkü her rasgele
deðiþkenin daðýlýmýnýn ayný olduðunu kabul etmiþtik. Her yazý tura ayný
þartlar altýnda atýlmazlar mý?

$\bar{X_n}$ de bir rasgele deðiþkendir, çünku Büyük sayýlar kanununu,
matematiksel olarak,$\bar{X_n}$ deðiþkeninin ortalamasýný tekil olarak her
Xi daðýlýmýnýn (ayný olan) ortalamasý arasýnda birkü onun da formülü baþka
rasgelen deðiþkenlere dayanýyor.

Ýspat devam etmek için, þapkalý Xn daðýlýmýnýn beklentisini bulmamýz gerekiyor. 

\[ \bar{X_n} = \frac{1}{n} \sum_{i=1}^n X_i  \]

\[ E(\bar{X_n}) = E(\frac{1}{n} \sum_{i=1}^n X_i)  \]

E dogrusal bir islec (linear operator) oldugu icin disaridan iceri dogru
nufuz eder. 

\[ = \frac{1}{n} \sum_{i=1}^n E(X_i) = \frac{1}{n}n\mu \]

\[ = \mu \]

$\bar{X_n}$ daðýlýmýnýn standart sapmasýný da bulalým. 

Diger bir olasilik kuramina gore

\[ Y = a + bX \]

\[ Var(Y) = b^2Var(X) \]

oldugunu biliyoruz. O zaman,

\[ \bar{X_n} = \frac{1}{n} \sum_{i=1}^n X_i  \]

\[ Var(\bar{X_n}) = Var(\frac{1}{n}\sum_{i=1}^nX_i) = 
\frac{1}{n^2}\sum_{i=1}^n Var(X_i)
\]

\[ Var(\bar{X_n}) = \frac{1}{n^2}\sum_{i=1}^n \sigma^2 = 
\frac{1}{n^2}n\sigma^2 = \frac{\sigma^2}{n} 
\]

Artýk Çebiþev kuramýný kullanmaya hazýrýz. 

$n \rightarrow \infty$, \[ P(|\bar{X_n}-\mu| > \epsilon) \rightarrow 0 \]

Cebisev'den

\[ P(|\bar{X_n}-\mu| > \epsilon) \le \frac{Var(\bar{X_n})}{\epsilon^2} \]

\[ P(|\bar{X_n}-\mu| > \epsilon) \le \frac{\sigma^2}{n\epsilon^2}
\rightarrow 0 \]

$\sigma^2 / n\epsilon^2$'in sifira gitmesi normal cunku n sonsuza gidiyor.

Peki $P(|\bar{X_n}-\mu| > \epsilon)$'nin sifira gittigini gosterdik mi? 

$\sigma^2 / n\epsilon^2$'nin sifira gittigini gosterdik. $\sigma^2 /
n\epsilon^2$ de $P(|\bar{X_n}-\mu| > \epsilon)$'den buyuk olduguna gore,
demek ki o da sifira iner. 

Çebiþev Eþitsizliði

Olasýlýk matematiðinde, büyük sayýlar kuramý adýnda anýlan ve olasýlýk
matematiðinin belkemiðini oluþturan kuramý ispatlamak için, diðer bir kuram
olan Çebiþev eþitsizliðini de anlamamýz gerekiyor. Çebiþev eþitsizliði bir
rasgele deðiþken, onun ortalamasý (beklentisi) ve herhangi bir sabit sayý
arasýndaki üçlü arasýnda bir 'eþitsizlik' baðlantýsý kurar, ve bu baðlantý
diðer olasýlýk iþlemlerimizde ispat verisi olarak iþimize yarar.

Teori: Herhangi bir $t$ deðeri için, 

\[ P(|X-\mu| > t) \le \frac{\sigma^2}{t^2} \]

Ýspata baþlayalým. Entegral ile olasýlýk hesabý yapmak için bize bir $x$
uzayý lazým.

\[ R = {x: |x-\mu| > t} \]

Yani R uzayý, $x$ ile ortalamasýnýn farkýnýn, $t$'den büyük olduðu bütün
sayýlarýn kümesidir.

O zaman, 

\[ P(|X-\mu| > t) = \int_R f(x)dx \]

Dikkat edelim $P(..)$ içindeki formül, küme tanýmý ile ayný. O yüzden $P()$
hesabý ortada daha olmayan, ama varolduðu kesin bir daðýlým fonksiyonu
tanýmlamýþ da oluyor. Buna $f(x)$ deriz. $P()$'in, $f(x)$ fonksiyonunun $R$
üzerinden entegral olduðunu olasýlýða giriþ dersinden bilmemiz lazým.

Eger $x \in R$ dersek o zaman

\[ \frac{|x-\mu|^2}{t^2} \ge 1 \]

t'nin denkleme bu þekilde nereden geldiði þaþkýnlýk yaratabilir. Daha önce
tanýmlanan þu ibareye dikkat edelim, $x: |x-u| > t$ diye belirtmiþtik. Bu
ifadeyi deðiþtirerek, yukarýdaki denkleme gelebiliriz.

Devam edersek, elimizdeki 1'den büyük bir deðer var. Bu deðeri kullanarak,
aþaðýdaki tanýmý yapmamýz doðru olacaktýr.

\[ \int_R f(x)dx \le \int_R \frac{(x-\mu)^2}{t^2}f(x)dx \le
\int_{-\infty}^{\infty}\frac{(x-\mu)^2}{t^2}f(x)dx 
 \]


Ortadaki entegral niye birinci entegralden büyük? Çünkü ortadaki entegraldeki
$F(x)dx$ ibaresinden önce gelen kýsmýn, her zaman 1'den büyük olacaðýný
belirttiðimize göre, ikinci entegralin birinciden büyük olmasý normaldir.

Evet...Üçüncü entegral ispata oldukça yaklaþtý aslýnda. Standart sapma
iþaretini hala ortada göremiyoruz, fakat son entegraldeki ibare standart
sapma deðerini zaten içeriyor. Önce daha önceki olasýlýk natematiði
bilgimize dayanarak, standart sapmanýn tanýmýný yazýyoruz. Dikkat edelim,
bu ibare þu anki ispatýmýz dahilinden deðil, haricinden önceki bilgimize
dayanarak geldi. Standart sapmanýn tanýmý þöyledir.

\[ \sigma^2 = \int_{-\infty}^{\infty} (x-\mu)^2f(x)dx \]

O zaman

\[ \frac{\sigma^2}{t^2} = \int_{-\infty}^{\infty}\frac{(x-\mu)^2}{t^2}f(x)dx \]

yani

\[ \int_R f(x)dx \le \frac{\sigma^2}{t^2} = 
\int_{-\infty}^{\infty} \frac{(x-\mu)^2}{t^2}f(x)dx
\]

ki $\int_R f(x)dx$ zaten $P(|X-\mu| > t)$ olarak tanimlanmisti. 


Kaynaklar

\verb!https://gist.github.com/mblondel/1761714!

Introductory Statistics with R

Introduction to Probability and Statistics Using R



\end{document}
