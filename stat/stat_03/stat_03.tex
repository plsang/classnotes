\documentclass[12pt,fleqn]{article}\usepackage{../common}
\begin{document}
Ders 3

Bilesen (Marginal) Dagilimlar 

Surekli rasgele degiskenler icin bilesen yogunluk 

\[ f_X(x) = \int f(x,y) dx \]

ve

\[ f_Y(y) = \int f(x,y) dy \]

Ornek 

$f_{X,Y}(x,y) = e^{ -(x+y)}$, olsun ki $x,y \ge 0$. O zaman $f_X(x)$

\[ f_X(x) = e^{ -x} \int _{ 0}^{\infty} e^{ -y}dy = e^{ -x}  \cdot 1  = e^{-x} 
\]

Ornek 

\[ f(x,y) = 
\left\{ \begin{array}{ll}
x+y & eger \ 0 \le x \le 1, \ 0 \le y \le 1 \\
0 & diger
\end{array} \right.
 \]

\[ f_Y(y) = \int _{0}^{1}(x+y) dx = 
\int _{0}^{1}x dx + \int _{0}^{1}y dx  = 
\frac{ 1}{2} + y 
\ \ \ \label{1}
 \]

Tanim 

Iki rasgele degisken $A,B$ bagimsizdir eger tum $A,B$ degerleri icin 

\[ P(X \in A, Y \in B) = P(X \in A)P(Y \in B) \]

esitligi dogru ise. Bu durumda $X \amalg Y$ yazilir.

Teori 

$X,Y$'nin birlesik PDF'i $f_{X,Y}$ olsun. O zaman ve sadece 
$f_{X,Y}(x,y) =
 f_X(x)f_Y(y)$ ise $X \amalg Y$ dogrudur. 

Ornek 

Diyelim ki $X,Y$ bagimsiz, ve ikisinin de ayni yogunlugu var.

\[ f(x) = 
\left\{ \begin{array}{ll}
2x & eger \ 0 \le x \le 1 \\
0 & digerleri
\end{array} \right.
 \]

$P(X+Y < 1)$'i hesaplayin. 

Cevap

Bagimsizligi kullanarak birlesik dagilimi hesaplayabiliriz

\[ f(x,y) = f_X(x)f_Y(y) = 
\left\{ \begin{array}{ll}
4xy & eger \ 0 \le x \le 1, \ \ 0 \le y \le 1 \\
0 & digerleri
\end{array} \right.
 \]

Simdi bu birlesik yogunluk uzerinden istedigimiz bolgeyi hesaplariz,
bolgeyi tanimlayan $X+Y \le 1$ ifadesi. 

\[ P(X+Y \le 1) = 
\int \int_{x+y \le 1} f(x,y) dy dx
 \]

Entegralin limiti ustteki hali sembolik, hesap icin bu yeterli degil, eger
$x+y \le 1$ ise,  $y \le 1-x$ demektir, ve bolge $y = 1-x$ cizgisinin alti
olarak kabul edilebilir. $x,y$ zaten sifirdan buyuk olmali, yani sola dogru
yatik cizginin alti ve $y,x$ eksenlerinin ustu kismini olusturan bir ucgen,

\[ =
\int _{ 0}^{1} \int _{ 0}^{1-x} 4yx \ dy dx = 
4 \int \int _{ 0}^{1} x \bigg[ \int _{ 0}^{1-x} ydy \bigg] dx
 \]

Numaraya dikkat, hangi degisken uzerinden entegral aldigimiza bakarak, onun
haricindekileri sabit kabul ederek bu ``sabitleri'' entegral disina
atiyoruz, boylece isimizi kolaylastiriyoruz. Hesabi tamamlarsak, 

\[ 4 \int _{ 0}^{1} x \frac{ (1- x)^2}{2} dx = \frac{ 1}{6} \]

Kosullu Dagilimlar (Conditional Distributions)

Surekli rasgele degiskenler icin kosullu olasilik yogunluk fonksiyonlari 

\[ f_{X|Y}(x|y) = \frac{ f_{X,Y}(x,y)}{f_Y(y)} \]

Devam edelim, eger kosullu yogunluk uzerinden olay hesabi yapmak istersek,
ve  $f_Y(y) > 0$ oldugunu farzederek, 

\[ P(X \in A | Y = y) = \int_A f_{X|Y}(x|y) dx \]


Ornek 

(1) sonucunu aldigimiz ornege donelim,

\[ f(x,y) = 
\left\{ \begin{array}{ll}
x+y & eger \ 0 \le x \le 1, \ 0 \le y \le 1 \\
0 & diger
\end{array} \right.
 \]

$P(X < 1/4 | Y = 1/3)$ nedir? 

Cevap 

Ustteki olasilik hesabi icin $f_{X|Y}$ fonksiyonuna ihtiyacimiz var. (1)'de
gordugumu uzere, 

\[ f_Y(y) = \frac{ 1}{2} + y 
 \]
 
Ana formulumuz neydi? 

\[ f_{X|Y}(x|y) = \frac{ f_{X,Y}(x,y)}{f_Y(y)} \]

\[ = 
\frac{ x+y }{\frac{ 1}{2} + y}
 \]


\[ P(X < 1/4 | Y = 1/3) = 
\int _{ 0}^{1/4} \frac{ x+ \frac{ 1}{3} }{\frac{ 1}{2} + \frac{1 }{3}} dx = 
\frac{ \frac{ 1}{32}+ \frac{ 1}{3} }{\frac{ 1}{2} + \frac{1 }{3}} = 
\frac{ 14}{32}
\]

Cok Degiskenli (Multivariate) Dagilimlar ve IID Orneklemler (Samples)

$X = (X_1,...,X_n)$ olsun, ki $(X_1,...,X_n)$'lerin herbiri bir rasgele
degisken, o zaman $X$'e rasgele vektor (random vector) ismi
verilir. $f(x_1,...,x_n)$'in PDF'i temsil ettigini dusunelim. Bu PDF'i baz
alarak aynen iki degiskenli (bivariate) orneklerde oldugu gibi, benzer
tekniklerle bilesenleri, kosullu dagilimlari, vs. hesaplamak mumkundur.

Cok Degiskenli Normal 

Tek degiskenli Normal dagilimin iki parametresi vardi, $\mu,\sigma$. Cok
degiskenli formda $\mu$ bir vektor, $\sigma$ yerine ise $\Sigma$ matrisi
var. Once rasgele degiskeni tanimlayalim,

\[ Z = 
\left[\begin{array}{r}
Z_1 \\ \vdots \\ Z_k
\end{array}\right]
 \]

ki $Z_1,...,Z_k \sim N(0,1)$. $Z$'nin yogunlugu 

\[ f(z) = \prod _{ i=1}^{k}f(z_i) = 
\frac{ 1}{(2\pi)^{k/2}} \exp 
\bigg\{ 
-\frac{ 1}{2}\sum _{ j=1}^{k}z_j^2
\bigg\}
 \]

\[ =
\frac{ 1}{(2\pi)^{k/2}} \exp 
\bigg\{ 
-\frac{ 1}{2}z^Tz
\bigg\}
 \]


Bu durumda $Z$'nin {\em standart} cok degiskenli Normal dagilima sahip
oldugu soylenir, ve $Z \sim N(0,I)$ olarak gosterilir. Buradaki $0$
degeri icinde $k$ tane sifir olan bir vektor olarak, $I$ ise $k \times k$
birim (identity) matrisi olarak anlasilmalidir. 

Daha genel olarak bir vektor $X$'in cok degiskenli Normal dagilimina sahip
oldugunu soyleriz, ve bunu $X \sim N(\mu,\Sigma)$ olarak gosteririz, eger
dagilimin yogunlugu 

\[ f(x;\mu,\Sigma) = 
\frac{ 1}{(2\pi)^{k/2} \det(\Sigma)^{1/2}} \exp 
\bigg\{ 
-\frac{ 1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)
\bigg\}
 \]

$\Sigma$ pozitif kesin (positive definite) bir matristir. Hatirlayalim, bir matris
pozitif kesindir eger tum sifir olmayan $x$ vektorleri icin $x^T\Sigma x >
0$ ise. 

Not: Karekok kavrami tekil sayilardan matrislere de aktarilabilir. Bir
matris $B$'nin $A$'nin karekoku oldugu soylenir, eger $B \cdot B = A$ ise.

Devam edersek, eger $\Sigma$ pozitif kesin ise bir $\Sigma^{1/2}$ matrisini
oldugu gosterilebilir, ki bu matrise $\Sigma$'nin karekoku ismi verilir, ve
bu karekokun su ozellikleri vardir, (i)  $\Sigma^{1/2}$ simetriktir, (ii)
$\Sigma =  \Sigma^{1/2}\Sigma^{1/2} = I$ ve $\Sigma^{-1/2} =
(\Sigma^{1/2})^{-1}$. 

Diyelim ki Normal bir vektor $X$'i $X = (X_1,X_2)$ olarak parcaladik. Ayni
sekilde $\mu = (\mu_1,\mu_2)$ olarak parcalayabiliriz. $\Sigma$ ise

\[ \Sigma = 
\left[\begin{array}{rr}
\Sigma_{11} & \Sigma_{12}\\
\Sigma_{21} & \Sigma_{22}
\end{array}\right]
 \]

olarak parcalanabilir. $a,b$'nin parcalarinin boyutlari $p,q$ olsun, $n =
p+q$.

Simdi birlesik Gaussian'i 

\[ f(x;\mu,\Sigma) = 
\frac{ 1}{(2\pi)^{(p+q)/2} \det(\Sigma)^{1/2}} 
\exp 
\bigg\{ 
-\frac{ 1}{2}
\left[\begin{array}{r}
x_1 - \mu_1\\
x_2 - \mu_2
\end{array}\right]^T
\left[\begin{array}{rr}
\Sigma_{11} & \Sigma_{12}\\
\Sigma_{21} & \Sigma_{22}
\end{array}\right]^{-1}
\left[\begin{array}{r}
x_1 - \mu_1\\
x_2 - \mu_2
\end{array}\right]
\bigg\}
 \]

Birlesik yogunlugu parcalar uzerinden belirtirsek, bu yogunlugu $X_2$ icin
bilesen yogunluga ve $X_1$ icin bir kosullu yogunluga ayirabiliriz. Yani 

\[ f(x_1,x_2) = f(x_1|x_2) f(x_2) \]

tanimindaki parcalari elde etmeye calisacagiz.  Ama bundan once
boluntulenmis matrislere yakindan bakalim. 

Bir boluntulenmis (partitioned) matrisin tersini almak icin, o matrisin
parcalarinin tersini almak dogru degildir, yani

\[ 
\left[\begin{array}{rr}
E & F \\
G & H
\end{array}\right] ^{-1} \ne
\left[\begin{array}{rr}
E^{-1} & F ^{-1}\\
G^{-1} & H^{-1}
\end{array}\right]  
 \]

Tersini alma islemi icin bazi numaralar lazim. Ana numara boluntulenmis matrisi 
kosegen bir matris haline getirmek, cunku kosegen matrislerin tersi,
kosegendeki elemanlarin tersidir, yani ters alma operasyonu bu tur
matrislerin ``icine isler'', o yuzden bir sekilde bir kosegen matris
elde etmeye ugrasacagiz. Bunun icin boluntulenmis matrisimizi sagdan ve
soldan bazi matrislerle carpacagiz. Ayrica sunu da bilelim, 

\[ XYZ = W \]

durumunda $Y$'nin tersini almak istersek, sag ve soldaki $X,Z$
matrislerinin tersini almak gerekmez, niye?

\[ X^{-1}XYZ = X^{-1}W \]

\[ YZZ^{-1} = X^{-1}WZ^{-1} \]

\[ Y = X^{-1}WZ^{-1} \]

Simdi iki tarafin da tersini alalim, 

\[ Y^{-1} = ZW^{-1}X \]

Tamam, baslayalim. 

\[ M = 
\left[\begin{array}{rr}
E & F \\
G & H
\end{array}\right] 
 \]

matrisini kosegen yapacagiz. Eger sadece alt sol koseyi sifirlayasaydik, 
bunu yapacak ozel bir matrisle soldan carpardik,

\[ 
\left[\begin{array}{rr}
I & -FH^{-1} \\
0 & I
\end{array}\right] 
\left[\begin{array}{rr}
E & F \\
G & H
\end{array}\right] = 
\left[\begin{array}{rr}
E & F \\
0 & H
\end{array}\right] 
 \]

Sadece ust sag koseyi sifirlamak isteseydik, sagdan carpardik

\[ 
\left[\begin{array}{rr}
E & F \\
G & H
\end{array}\right] 
\left[\begin{array}{rr}
I & 0 \\
-H^{-1}G & I
\end{array}\right] 
=
\left[\begin{array}{rr}
E & 0 \\
G & H
\end{array}\right] 
 \]

Hepsini biraraya koyalim, 

\[ 
\left[\begin{array}{rr}
I & -FH^{-1} \\
0 & I
\end{array}\right] 
\left[\begin{array}{rr}
E & F \\
G & H
\end{array}\right] 
\left[\begin{array}{rr}
I & 0 \\
-H^{-1}G & I
\end{array}\right] 
= 
\left[\begin{array}{rr}
E-FH^{-1}G & 0 \\
0 & H
\end{array}\right] 
\ \ \ \label{2}
 \]

Bu carpimin dogrulugu carpim elle yapilarak kontrol edilebilir.

Ustte gordugumuz gibi 

\[ XYZ = W \]

ifadesindeki $Y$'nin tersi 

\[ Y^{-1} = ZW^{-1}X \]

ile olur. 

\[ 
\underbrace{
\left[\begin{array}{rr}
I & -FH^{-1} \\
0 & I
\end{array}\right] 
}_{X}
\underbrace{
\left[\begin{array}{rr}
E & F \\
G & H
\end{array}\right] 
}_{Y}
\underbrace{
\left[\begin{array}{rr}
I & 0 \\
-H^{-1}G & I
\end{array}\right] 
}_{Z}
= 
\underbrace{
\left[\begin{array}{rr}
E-FH^{-1}G & 0 \\
0 & H
\end{array}\right] 
}_{W}
 \]


O zaman 

\[ 
\left[\begin{array}{rr}
E & F \\
G & H
\end{array}\right]^{-1}
=
\left[\begin{array}{rr}
I & 0 \\
-H^{-1}G & I
\end{array}\right] 
\left[\begin{array}{rr}
E-FH^{-1}G & 0 \\
0 & H
\end{array}\right]^{-1}
\left[\begin{array}{rr}
I & -FH^{-1} \\
0 & I
\end{array}\right] 
 \]

Daha kisa olmasi esitligin sag tarafinda, ortadaki matris icin
$E-FH^{-1}G$ yerine $M/H$ kullanalim (bu arada $M/H$ lineer cebirde ``$M$'in
$H$'e gore Schur tamamlayicisi (complement)'' olarak bilinir),

\[ 
\left[\begin{array}{rr}
E & F \\
G & H
\end{array}\right]^{-1}
=
\left[\begin{array}{rr}
I & 0 \\
-H^{-1}G & I
\end{array}\right] 
\left[\begin{array}{rr}
(M/H)^{-1} & 0 \\
0 & H^{-1}
\end{array}\right]
\left[\begin{array}{rr}
I & -FH^{-1} \\
0 & I
\end{array}\right] 
\ \ \ \label{3}
 \]

Esitligin sag tarafindaki carpimi gerceklestirirsek, 

\[ =
\left[\begin{array}{rr}
(M/H)^{-1} & -(M/H)^{-1}FH^{-1} \\
-H^{-1}G(M/H)^{-1} & H^{-1}+H^{-1}G(M/H)^{-1}FH^{-1} 
\end{array}\right]
 \]

Bu final ifade boluntulenmis bir matrisin tersini o matrisin icindeki parcalar
uzerinden temsil eden bir ifadedir. 

Icinde bir kosesi sifir olan boluntulenmis matrislerde determinantlar soyle
isler,

\[ 
det \bigg(
\left[\begin{array}{rr}
E & 0 \\
G & H
\end{array}\right]
\bigg) 
= 
det \bigg(
\left[\begin{array}{rr}
E & F \\
0 & H
\end{array}\right] 
\bigg) =
det(E)det(H)
 \]

Ayrica 

\[ det(AB) = det(A)det(B) \]

O zaman (2)'nin determinantini alirsak, $\det$ yerine $||$ kullandik, 

\[ |M| = |M/H||H| 
\ \ \ \label{4}
\]

Bu ifade gayet dogal duruyor (bir raslanti herhalde, ya da Schur tamamlayicisi 
isareti ozellikle boyle secilmis),

Boluntulenmis bir matrisin devrigini almak icin her blogunun ayri ayri devrigi
alinir, ve tum bloklarin yani boluntulenmis tamaminin bir daha devrigi
alinir, yani

\[ 
\left[\begin{array}{rr}
A & B \\ C & D 
\end{array}\right]^T = 
\left[\begin{array}{rr}
A^T & C^T \\ B^T & D^T
\end{array}\right]
 \]

Simdi cok degiskenli Normal icin bilesen ve kosullu yogunluk hesaplarina
gelelim. Gaussian formulunun $\exp$ kismini alirsak, 

\[ \exp 
\bigg\{ 
-\frac{ 1}{2}
\left[\begin{array}{r}
x_1 - \mu_1\\
x_2 - \mu_2
\end{array}\right]^T
\left[\begin{array}{rr}
\Sigma_{11} & \Sigma_{12}\\
\Sigma_{21} & \Sigma_{22}
\end{array}\right]^{-1}
\left[\begin{array}{r}
x_1 - \mu_1\\
x_2 - \mu_2
\end{array}\right]
\bigg\}
 \]


(3)'teki acilimi kullanirsak, ve $E = \Sigma_{11},F=\Sigma_{12},..$ olacak sekilde,

\[ \exp 
\bigg\{ 
-\frac{ 1}{2}
\left[\begin{array}{r}
x_1 - \mu_1\\
x_2 - \mu_2
\end{array}\right]^T
\left[\begin{array}{rr}
I & 0 \\ 
-\Sigma_{22}^{-1}\Sigma_{21} & I
\end{array}\right]
\left[\begin{array}{rr}
(\Sigma/\Sigma_{22}) & 0 \\ 
0 & \Sigma_{22}^{-1} 
\end{array}\right]
\left[\begin{array}{rr}
I & -\Sigma_{12}\Sigma_{22}^{-1}  \\ 
0 & I
\end{array}\right]
\left[\begin{array}{r}
x_1 - \mu_1\\
x_2 - \mu_2
\end{array}\right]
\bigg\}
 \]


Acilimi tamamen yaparsak, 

\[ 
 \begin{array}{lll}
= && \exp \bigg\{
-\frac{1 }{2} 
(x_1 - \mu_1 - \Sigma_{12}\Sigma_{22}^{-1} (x_2 - \mu_2))^T 
(\Sigma/\Sigma_{22})^{-1} 
(x_1 - \mu_1 - \Sigma_{12}\Sigma_{22}^{-1} (x_2 - \mu_2))
\bigg\} \cdot \\
&& \exp \bigg\{
1\frac{ 1}{2}(x_2-\mu_2)^T\Sigma_{22}^{-1} (x_2-\mu_2)
 \bigg\}
\end{array}
 \]

Not: $\Sigma_{12}^T = \Sigma_{21}$. Ustte birinci $\exp$ icinde sol bolumde devrigin icindeki ifadelerden,  
mesela $x_1^T,\mu_1^T$'den ve $\Sigma_{21}$'li ifadeden devrik islemini cekip, buyuk paranteze 
alininca bu degisim oldu. 

Simdi mesela 1. $\exp$'ye dikkat edersek, ortada $(\Sigma/\Sigma_{22})^{-1} $ var, ve bu ifadenin solunda ve saginda 
birbirinin devrigi olan ayni terimler duruyor. Ifadenin tamami bir Normal
dagilim. Ayni sey 2. $\exp$ icin gecerli. 

Isin $\exp$ tarafini halletik. Simdi $\exp$ oncesindeki kesiri (4) kullanarak
parcalayalim, 

\[ 
\frac{ 1}{(2\pi)^{(p+q)/2} \det(\Sigma)^{1/2}}  = 
\frac{ 1}{(2\pi)^{(p+q)/2} \bigg(\det(\Sigma/\Sigma_{22})\det(\Sigma_{22})\bigg)^{1/2}} 
 \]

\[ =
\bigg( \frac{ 1}{(2\pi)^{p/2} \det(\Sigma/\Sigma_{22})^{1/2}} \bigg)
\bigg( \frac{ 1}{(2\pi)^{q/2} \det(\Sigma_{22})^{1/2}} \bigg)
 \]

Bu parcalarin her birini ayri bir $\exp$ onunde kullanabiliriz, ve ikinci $\exp$
ifadesinin 

\[ 
\frac{ 1}{(2\pi)^{q/2} \det(\Sigma_{22})^{1/2}}
\exp \bigg\{
\frac{ 1}{2}(x_2-\mu_2)^T\Sigma_{22}^{-1} (x_2-\mu_2)
 \bigg\}
 \]


oldugunu goruyoruz. Bu ifade $f(x_2)$ bilesen yogunlugudur! O zaman geri
kalanlar, yani diger kesir ve birinci $\exp$ hep beraber $f(x_1|x_2)$
yogunlugu olmalidir. Yani,

\[ 
\frac{ 1}{(2\pi)^{p/2} \det(\Sigma/\Sigma_{22})^{1/2}} \cdot
 \]
\[ 
\exp \bigg\{
-\frac{1 }{2} 
(x_1 - \mu_1 - \Sigma_{12}\Sigma_{22}^{-1} (x_2 - \mu_2))^T 
(\Sigma/\Sigma_{22})^{-1} 
(x_1 - \mu_1 - \Sigma_{12}\Sigma_{22}^{-1} (x_2 - \mu_2))
\bigg\}
 \]

Buradan genel bir kural cikartabiliriz, 

(1) $X_2$'nin bilesen yogunlugu $X_2 \sim N(\mu_2, \Sigma_{22})$

(2) $X_2 = x_2$ olmak uzere $X_1$'in kosullu dagilimi 

\[ X_1 | X_2 = x_2 \sim 
N\bigg(\mu_1 + \Sigma_{12}\Sigma_{22}^{-1} (x_2 -\mu_2) \ , \
\Sigma/\Sigma_{22} \bigg)
 \]

$\Sigma/\Sigma_{22}$ nedir? Hatirlarsak, $M/H = E-FH^{-1}G$, ve 
$E = \Sigma_{11},F=\Sigma_{12},..$ o zaman 

\[ \Sigma/\Sigma_{22} = \Sigma_{11}-\Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21} \]

Yani

\[ X_1 | X_2 = x_2 \sim 
N\bigg(\mu_1 + \Sigma_{12}\Sigma_{22}^{-1} (x_2 -\mu_2) \ , \
\Sigma_{11}-\Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21}
\bigg)
 \]



\end{document}
