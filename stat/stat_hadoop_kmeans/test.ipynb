{
 "metadata": {
  "name": "patent"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "source": [
      "Hadoop ile Patent Verisi Islemek\n",
      "\n",
      "75-99 yillari arasinda hangi patentin hangi hangi patentlere referans\n",
      "verdigi ve patentler hakkinda detayli verileri Hadoop ile\n",
      "isleyecegiz. Veriler alttaki baglantidan alinabilir, gerekli dosyalar\n",
      "Dosyalar <code>cite75_99.txt</code> ve <code>apat63_99.txt</code>. Bu dosyalari\n",
      "acip biz <code>$HOME/Downloads</code> altina koyduk. \n",
      "\n",
      "http://www.nber.org/patents/\n",
      "\n",
      "Referans verisine bakarsak,"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head -10 $HOME/Downloads/cite75_99.txt"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\"CITING\",\"CITED\"\r\n",
        "3858241,956203\r\n",
        "3858241,1324234\r\n",
        "3858241,3398406\r\n",
        "3858241,3557384\r\n",
        "3858241,3634889\r\n",
        "3858242,1515701\r\n",
        "3858242,3319261\r\n",
        "3858242,3668705\r\n",
        "3858242,3707004\r\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "source": [
      "Bu veri, hangi patentin hangi diger patenti kullandigini \"tek\" patent\n",
      "bazinda gostermekte. Detayli patent verisine bakalim"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head -10 $HOME/Downloads/apat63_99.txt"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\"PATENT\",\"GYEAR\",\"GDATE\",\"APPYEAR\",\"COUNTRY\",\"POSTATE\",\"ASSIGNEE\",\"ASSCODE\",\"CLAIMS\",\"NCLASS\",\"CAT\",\"SUBCAT\",\"CMADE\",\"CRECEIVE\",\"RATIOCIT\",\"GENERAL\",\"ORIGINAL\",\"FWDAPLAG\",\"BCKGTLAG\",\"SELFCTUB\",\"SELFCTLB\",\"SECDUPBD\",\"SECDLWBD\"\r\n",
        "3070801,1963,1096,,\"BE\",\"\",,1,,269,6,69,,1,,0,,,,,,,\r\n",
        "3070802,1963,1096,,\"US\",\"TX\",,1,,2,6,63,,0,,,,,,,,,\r\n",
        "3070803,1963,1096,,\"US\",\"IL\",,1,,2,6,63,,9,,0.3704,,,,,,,\r\n",
        "3070804,1963,1096,,\"US\",\"OH\",,1,,2,6,63,,3,,0.6667,,,,,,,\r\n",
        "3070805,1963,1096,,\"US\",\"CA\",,1,,2,6,63,,1,,0,,,,,,,\r\n",
        "3070806,1963,1096,,\"US\",\"PA\",,1,,2,6,63,,0,,,,,,,,,\r\n",
        "3070807,1963,1096,,\"US\",\"OH\",,1,,623,3,39,,3,,0.4444,,,,,,,\r\n",
        "3070808,1963,1096,,\"US\",\"IA\",,1,,623,3,39,,4,,0.375,,,,,,,\r\n",
        "3070809,1963,1096,,\"US\",\"AZ\",,1,,4,6,65,,0,,,,,,,,,\r\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "source": [
      "Simdi patent detay verisinden bir orneklem (sample) alalim. Daha ufak bir\n",
      "veri kumesiyle calismak ilk basta faydali olabilir, gelistirme test etme\n",
      "surecini hizlandirir."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!chmod a+r $HOME/Downloads/apat63_99.txt\n",
      "!head -1 $HOME/Downloads/apat63_99.txt > $HOME/Downloads/apat63_99_sampled.txt\n",
      "!cat $HOME/Downloads/apat63_99.txt | perl -n -e 'print if (rand() < .05)' >> $HOME/Downloads/apat63_99_sampled.txt"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "source": [
      "Hadoop baslatalim"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ssh localhost -l hduser /home/hduser/Downloads/hadoop*/bin/stop-all.sh\n",
      "!ssh localhost -l hduser /home/hduser/Downloads/hadoop*/bin/start-all.sh"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "no jobtracker to stop\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "localhost: no tasktracker to stop\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "no namenode to stop\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "localhost: no datanode to stop\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "localhost: no secondarynamenode to stop\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting namenode, logging to /home/hduser/Downloads/hadoop-1.0.4/libexec/../logs/hadoop-hduser-namenode-burak-Aspire-S3.out\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "localhost: starting datanode, logging to /home/hduser/Downloads/hadoop-1.0.4/libexec/../logs/hadoop-hduser-datanode-burak-Aspire-S3.out\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "localhost: starting secondarynamenode, logging to /home/hduser/Downloads/hadoop-1.0.4/libexec/../logs/hadoop-hduser-secondarynamenode-burak-Aspire-S3.out\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting jobtracker, logging to /home/hduser/Downloads/hadoop-1.0.4/libexec/../logs/hadoop-hduser-jobtracker-burak-Aspire-S3.out\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "localhost: starting tasktracker, logging to /home/hduser/Downloads/hadoop-1.0.4/libexec/../logs/hadoop-hduser-tasktracker-burak-Aspire-S3.out\r\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "/home/hduser/Downloads/hadoop*/bin/hadoop dfs -mkdir /user/hduser/patent"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ssh localhost -l hduser /home/hduser/Downloads/hadoop*/bin/hadoop dfs -ls /user/hduser/patent"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Found 2 items\r\n",
        "-rw-r--r--   1 hduser supergroup  236903179 2013-02-21 14:16 /user/hduser/patent/apat63_99.txt\r\n",
        "-rw-r--r--   1 hduser supergroup   11878646 2013-02-21 16:36 /user/hduser/patent/apat63_99_sampled.txt\r\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ssh localhost -l hduser /home/hduser/Downloads/hadoop*/bin/hadoop dfs -copyFromLocal $HOME/Downloads/apat63_99_sampled.txt /user/hduser/patent/apat63_99_sampled.txt"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "copyFromLocal: Target /user/hduser/patent/apat63_99_sampled.txt already exists\r\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "source": [
      "Amacimiz patent verisindeki ulke (country) kodunu kullanarak her ulke\n",
      "basina ortalama ne kadar patent uretildigini\n",
      "hesaplamak. Esleme-Indirgeme (Map-Reduce) dongusunde esleme kismini\n",
      "yapacak program asagida."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print open(\"mapper.py\").read()"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "#!/usr/bin/python\n",
        "import os,sys\n",
        "os.environ['MPLCONFIGDIR']='/tmp' \n",
        "import pandas as pd\n",
        "data = pd.read_csv(sys.stdin,sep=\",\",index_col=0,usecols=[0,4,8])\n",
        "df = data[pd.notnull(data.ix[:,0]) & pd.notnull(data.ix[:,1])].ix[:,0:2]\n",
        "df.to_csv(sys.stdout,sep=\"\\t\",index=False,header=False)\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "source": [
      "Indirgeyici yazmadan once programimizi iki sekilde test edelim. Bu\n",
      "sekillerden birisi hic indirgeyici olmadan, ikincisi\n",
      "<code>IdentityReducer</code> denen kendisine gecilen veriyi oldugu\n",
      "gibi disari atan (ama yine de ortada bir indirgeyici oldugu icin\n",
      "sonradan bazi islemlerin yine de yapildigi) seklinde. Bu iki kullanim\n",
      "Hadoop kodlarinda hata bulma / temizleme icin faydali olabiliyor."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cp mapper.py /tmp/\n",
      "!chmod a+r /tmp/mapper.py\n",
      "!chmod a+x /tmp/mapper.py"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ssh localhost -l hduser /home/hduser/Downloads/hadoop*/bin/hadoop dfs -rmr /user/hduser/output\n",
      "!ssh localhost -l hduser /home/hduser/Downloads/hadoop*/bin/hadoop  jar /home/hduser/Downloads/hadoop*/contrib/streaming/hadoop-*streaming*.jar -input patent/apat63_99_sampled.txt  -output output  -mapper /tmp/mapper.py -numReduceTasks 0 "
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Deleted hdfs://localhost:54310/user/hduser/output\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "packageJobJar: [/app/hadoop/tmp/hadoop-unjar2555196345671652661/] [] /tmp/streamjob5013687273729997973.jar tmpDir=null\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13/02/24 16:30:26 INFO util.NativeCodeLoader: Loaded the native-hadoop library\r\n",
        "13/02/24 16:30:26 WARN snappy.LoadSnappy: Snappy native library not loaded\r\n",
        "13/02/24 16:30:26 INFO mapred.FileInputFormat: Total input paths to process : 1\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13/02/24 16:30:27 INFO streaming.StreamJob: getLocalDirs(): [/app/hadoop/tmp/mapred/local]\r\n",
        "13/02/24 16:30:27 INFO streaming.StreamJob: Running job: job_201302241611_0012\r\n",
        "13/02/24 16:30:27 INFO streaming.StreamJob: To kill this job, run:\r\n",
        "13/02/24 16:30:27 INFO streaming.StreamJob: /home/hduser/Downloads/hadoop-1.0.4/libexec/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201302241611_0012\r\n",
        "13/02/24 16:30:27 INFO streaming.StreamJob: Tracking URL: http://localhost:50030/jobdetails.jsp?jobid=job_201302241611_0012\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13/02/24 16:30:28 INFO streaming.StreamJob:  map 0%  reduce 0%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13/02/24 16:30:43 INFO streaming.StreamJob:  map 100%  reduce 0%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13/02/24 16:30:49 INFO streaming.StreamJob:  map 100%  reduce 100%\r\n",
        "13/02/24 16:30:49 INFO streaming.StreamJob: Job complete: job_201302241611_0012\r\n",
        "13/02/24 16:30:49 INFO streaming.StreamJob: Output: output\r\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ssh localhost -l hduser /home/hduser/Downloads/hadoop*/bin/hadoop dfs  -copyToLocal output /tmp/\n",
      "!head -20 /tmp/output/part-00000"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "AD\t14.0\r\n",
        "AE\t15.4\r\n",
        "AG\t13.25\r\n",
        "AI\t10.0\r\n",
        "AM\t18.0\r\n",
        "AN\t9.625\r\n",
        "AR\t9.188990825688073\r\n",
        "AT\t10.683988393563704\r\n",
        "AU\t12.291563832174107\r\n",
        "AW\t15.5\r\n",
        "AZ\t11.0\r\n",
        "BB\t11.0\r\n",
        "BE\t11.945544554455445\r\n",
        "BG\t4.9899497487437188\r\n",
        "BH\t6.5\r\n",
        "BM\t10.076923076923077\r\n",
        "BN\t9.0\r\n",
        "BO\t11.75\r\n",
        "BR\t9.358426966292134\r\n",
        "BS\t15.778846153846153\r\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "source": [
      "Ustteki sonucta goruyoruz ki anahtarlar uretilmis, ama ciktilar\n",
      "anahtara gore siralanmamislar. Hatta ustteki sira girdi sirasiyla\n",
      "tipatip ayni. Simdi <code>IdentityReducer</code> uzerinden."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ssh localhost -l hduser /home/hduser/Downloads/hadoop*/bin/hadoop dfs -rmr /user/hduser/output\n",
      "!ssh localhost -l hduser /home/hduser/Downloads/hadoop*/bin/hadoop  jar /home/hduser/Downloads/hadoop*/contrib/streaming/hadoop-*streaming*.jar -input patent/apat63_99_sampled.txt  -output output  -mapper /tmp/mapper.py -reducer org.apache.hadoop.mapred.lib.IdentityReducer -numReduceTasks 1 "
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Deleted hdfs://localhost:54310/user/hduser/output\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "packageJobJar: [/app/hadoop/tmp/hadoop-unjar2314287838929839696/] [] /tmp/streamjob5231815242060775825.jar tmpDir=null\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13/02/24 18:03:14 INFO util.NativeCodeLoader: Loaded the native-hadoop library\r\n",
        "13/02/24 18:03:14 WARN snappy.LoadSnappy: Snappy native library not loaded\r\n",
        "13/02/24 18:03:14 INFO mapred.FileInputFormat: Total input paths to process : 1\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13/02/24 18:03:14 INFO streaming.StreamJob: getLocalDirs(): [/app/hadoop/tmp/mapred/local]\r\n",
        "13/02/24 18:03:14 INFO streaming.StreamJob: Running job: job_201302241759_0004\r\n",
        "13/02/24 18:03:14 INFO streaming.StreamJob: To kill this job, run:\r\n",
        "13/02/24 18:03:14 INFO streaming.StreamJob: /home/hduser/Downloads/hadoop-1.0.4/libexec/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201302241759_0004\r\n",
        "13/02/24 18:03:14 INFO streaming.StreamJob: Tracking URL: http://localhost:50030/jobdetails.jsp?jobid=job_201302241759_0004\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13/02/24 18:03:15 INFO streaming.StreamJob:  map 0%  reduce 0%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13/02/24 18:03:28 INFO streaming.StreamJob:  map 50%  reduce 0%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13/02/24 18:03:31 INFO streaming.StreamJob:  map 100%  reduce 0%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13/02/24 18:03:40 INFO streaming.StreamJob:  map 100%  reduce 100%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13/02/24 18:03:46 INFO streaming.StreamJob: Job complete: job_201302241759_0004\r\n",
        "13/02/24 18:03:46 INFO streaming.StreamJob: Output: output\r\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ssh localhost -l hduser rm -rf /tmp/output\n",
      "!ssh localhost -l hduser /home/hduser/Downloads/hadoop*/bin/hadoop dfs  -copyToLocal output /tmp/\n",
      "!head -10 /tmp/output/part-00000"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "FR\t12.0\r\n",
        "US\t5.0\r\n",
        "US\t1.0\r\n",
        "US\t4.0\r\n",
        "US\t4.0\r\n",
        "US\t21.0\r\n",
        "US\t4.0\r\n",
        "US\t8.0\r\n",
        "US\t7.0\r\n",
        "US\t11.0\r\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "source": [
      "Ustteki sonucta anahtarlarin siralanmis oldugunu goruyoruz.\n",
      "\n",
      "Simdi bir indirgeyici (reducer) ekleyelim. Bu indirgeyici ulke bazindaki\n",
      "veriler uzerinen ortalama alacak. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print open(\"reducer.py\").read()"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "#!/usr/bin/python\n",
        "import os,sys\n",
        "os.environ['MPLCONFIGDIR']='/tmp' \n",
        "import pandas as pd\n",
        "data = pd.read_csv(sys.stdin,sep=\"\\t\",names=['country','count'])\n",
        "grouped = data.groupby('country').mean()\n",
        "grouped.to_csv(sys.stdout,sep=\"\\t\",header=False)\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "source": [
      "Eger indirgeyiciyi direk isletirsek (Hadoop disindan)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cat /tmp/output/part-00000 | ./reducer.py | tail -10"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "SE\t9.0021739130434781\r\n",
        "SG\t14.0\r\n",
        "SU\t6.4136125654450264\r\n",
        "SV\t6.5\r\n",
        "TR\t8.0\r\n",
        "TW\t6.2037037037037033\r\n",
        "US\t10.964136780650541\r\n",
        "VE\t9.3333333333333339\r\n",
        "YU\t5.75\r\n",
        "ZA\t11.170212765957446\r\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "source": [
      "Bu kodu <code>hduser</code>'in bulabilecegi bir yere koyuyoruz. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cp reducer.py /tmp/\n",
      "!chmod a+r /tmp/reducer.py\n",
      "!chmod a+x /tmp/reducer.py"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ssh localhost -l hduser /home/hduser/Downloads/hadoop*/bin/hadoop dfs -rmr /user/hduser/output\n",
      "!ssh localhost -l hduser /home/hduser/Downloads/hadoop*/bin/hadoop  jar /home/hduser/Downloads/hadoop*/contrib/streaming/hadoop-*streaming*.jar -input patent/apat63_99_sampled.txt  -output output  -mapper /tmp/mapper.py -reducer /tmp/reducer.py -numReduceTasks 1 "
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Deleted hdfs://localhost:54310/user/hduser/output\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "packageJobJar: [/app/hadoop/tmp/hadoop-unjar3358838375062006941/] [] /tmp/streamjob3628714134396896316.jar tmpDir=null\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13/02/24 20:33:10 INFO util.NativeCodeLoader: Loaded the native-hadoop library\r\n",
        "13/02/24 20:33:10 WARN snappy.LoadSnappy: Snappy native library not loaded\r\n",
        "13/02/24 20:33:10 INFO mapred.FileInputFormat: Total input paths to process : 1\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13/02/24 20:33:10 INFO streaming.StreamJob: getLocalDirs(): [/app/hadoop/tmp/mapred/local]\r\n",
        "13/02/24 20:33:10 INFO streaming.StreamJob: Running job: job_201302241759_0005\r\n",
        "13/02/24 20:33:10 INFO streaming.StreamJob: To kill this job, run:\r\n",
        "13/02/24 20:33:10 INFO streaming.StreamJob: /home/hduser/Downloads/hadoop-1.0.4/libexec/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201302241759_0005\r\n",
        "13/02/24 20:33:10 INFO streaming.StreamJob: Tracking URL: http://localhost:50030/jobdetails.jsp?jobid=job_201302241759_0005\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13/02/24 20:33:11 INFO streaming.StreamJob:  map 0%  reduce 0%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13/02/24 20:33:23 INFO streaming.StreamJob:  map 50%  reduce 0%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13/02/24 20:33:26 INFO streaming.StreamJob:  map 100%  reduce 0%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13/02/24 20:33:35 INFO streaming.StreamJob:  map 100%  reduce 100%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13/02/24 20:33:42 INFO streaming.StreamJob: Job complete: job_201302241759_0005\r\n",
        "13/02/24 20:33:42 INFO streaming.StreamJob: Output: output\r\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ssh localhost -l hduser rm -rf /tmp/output\n",
      "!ssh localhost -l hduser /home/hduser/Downloads/hadoop*/bin/hadoop dfs  -copyToLocal output /tmp/"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "source": [
      "Ve sonuc altta oldugu gibi"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head -10 /tmp/output/part-00000"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "AE\t12.0\r\n",
        "AG\t24.0\r\n",
        "AN\t15.0\r\n",
        "AR\t10.359999999999999\r\n",
        "AT\t11.077306733167083\r\n",
        "AU\t12.789029535864978\r\n",
        "BE\t11.442748091603054\r\n",
        "BG\t4.5\r\n",
        "BM\t8.0\r\n",
        "BO\t25.0\r\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "source": [
      "Tabii bu sonuclar bir orneklem uzerinden alindi. Tum veriyi islemek icin"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ssh localhost -l hduser /home/hduser/Downloads/hadoop*/bin/hadoop dfs -copyFromLocal $HOME/Downloads/apat63_99.txt /user/hduser/patent/apat63_99.txt"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ssh localhost -l hduser /home/hduser/Downloads/hadoop*/bin/hadoop dfs -rmr /user/hduser/output\n",
      "!ssh localhost -l hduser /home/hduser/Downloads/hadoop*/bin/hadoop  jar /home/hduser/Downloads/hadoop*/contrib/streaming/hadoop-*streaming*.jar -input patent/apat63_99.txt  -output output  -mapper /tmp/mapper.py -reducer /tmp/reducer.py -numReduceTasks 1 "
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Deleted hdfs://localhost:54310/user/hduser/output\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "packageJobJar: [/app/hadoop/tmp/hadoop-unjar938213738183646678/] [] /tmp/streamjob7433279407208888397.jar tmpDir=null\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13/02/24 23:50:12 INFO util.NativeCodeLoader: Loaded the native-hadoop library\r\n",
        "13/02/24 23:50:12 WARN snappy.LoadSnappy: Snappy native library not loaded\r\n",
        "13/02/24 23:50:12 INFO mapred.FileInputFormat: Total input paths to process : 1\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13/02/24 23:50:12 INFO streaming.StreamJob: getLocalDirs(): [/app/hadoop/tmp/mapred/local]\r\n",
        "13/02/24 23:50:12 INFO streaming.StreamJob: Running job: job_201302241759_0006\r\n",
        "13/02/24 23:50:12 INFO streaming.StreamJob: To kill this job, run:\r\n",
        "13/02/24 23:50:12 INFO streaming.StreamJob: /home/hduser/Downloads/hadoop-1.0.4/libexec/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201302241759_0006\r\n",
        "13/02/24 23:50:12 INFO streaming.StreamJob: Tracking URL: http://localhost:50030/jobdetails.jsp?jobid=job_201302241759_0006\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13/02/24 23:50:13 INFO streaming.StreamJob:  map 0%  reduce 0%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13/02/24 23:50:28 INFO streaming.StreamJob:  map 50%  reduce 0%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13/02/24 23:50:40 INFO streaming.StreamJob:  map 75%  reduce 8%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13/02/24 23:50:52 INFO streaming.StreamJob:  map 100%  reduce 8%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13/02/24 23:50:55 INFO streaming.StreamJob:  map 100%  reduce 25%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13/02/24 23:51:04 INFO streaming.StreamJob:  map 100%  reduce 100%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13/02/24 23:51:17 INFO streaming.StreamJob: Job complete: job_201302241759_0006\r\n",
        "13/02/24 23:51:17 INFO streaming.StreamJob: Output: output\r\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ssh localhost -l hduser rm -rf /tmp/output\n",
      "!ssh localhost -l hduser /home/hduser/Downloads/hadoop*/bin/hadoop dfs  -copyToLocal output /tmp/"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head -7 /tmp/output/part-00000"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "AD\t14.0\r\n",
        "AE\t15.4\r\n",
        "AG\t13.25\r\n",
        "AI\t10.0\r\n",
        "AM\t18.0\r\n",
        "AN\t9.625\r\n",
        "AR\t9.188990825688073\r\n"
       ]
      }
     ],
     "prompt_number": 9
    }
   ]
  }
 ]
}